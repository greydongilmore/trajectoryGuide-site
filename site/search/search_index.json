{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["trimmer","stopWordFilter"]},"docs":[{"location":"index.html","title":"Home","text":"<p>An open-source software for neurosurgical trajectory planning, visualization, and postoperative assessment</p> <p>What is trajectoryGuide?</p> <p>trajectoryGuide provides the capability to plan surgical trajectories within 3D Slicer, an open-source medical imaging software. trajectoryGuide contains modules that span the three phases of neurosurgical trajectory planning:</p>"},{"location":"index.html#preoperative-features","title":"Preoperative features","text":"<ul> <li>automatic stereotactic frame detection (supported frames: Leksell, BRW, and CRW)</li> <li>co-registration of MRI and CT scans (incorporated registration algorithms: ANTS, FSL, or NiftyReg)</li> <li>trajectory planning providing coordinates in anatomical and stereotactic space (including arc, ring angles)</li> </ul>"},{"location":"index.html#perioperative-features","title":"Perioperative features","text":"<ul> <li>update final electrode position based on intra-operative testing</li> <li>display microelectrode recordings (MER) within the patients MRI space</li> </ul>"},{"location":"index.html#postoperative-features","title":"Postoperative features","text":"<ul> <li>electrode localization (using post-op imaging)</li> <li>visualize stimulation settings as volume of activated tissue</li> <li>view data within a template space (provided spaces: MNI152NLin2009bAsym, MNI152NLin2009cAsym, and PD25)</li> </ul>"},{"location":"about.html","title":"About","text":""},{"location":"about.html#neuronavigation","title":"Neuronavigation","text":"<p>The main goal of image guidance in neurosurgery is to accurately project magnetic resonance imaging (MRI) and/or computed tomography (CT) data into the operative field for defining anatomical landmarks, pathological structures and margins oftumors. To achieve this, \"neuronavigation\" software solutions have been developed to provide precise spatial information to neurosurgeons. Safe and accurate navigation of brain anatomy is of great importance when attempting to avoid important structures such as arteries and nerves.</p> <p>Neuronavigation software provides orientation information to the surgeon during all three phases of surgery: 1) pre-operative trajectory planning, 2) the intraoperative steroetactic procedure, and 3) post-operative visualization. Trajectory planning is performed prior to surgery using preoperative MRI data. On the day of surgery, the plans are transferred to sterotactic space using a frame or frame-less system. In both instances, a set of radiopaque fiducials are detected, providing the transformation matrix from anatomical space to sterotactic space. During the surgical procedure, the plans are updated according to intraoperative data collected (i.e. microelectrode recordings, electrode stimulation etc.). After the surgery, post-operative MRI or CT imaging confirms the actual position of the trajectory(ies).</p>"},{"location":"about.html#trajectoryguide","title":"trajectoryGuide?","text":"<p>trajectoryGuide is a surgical planning, visuazliation, and postoperative assessment tool used for various trajectory surguries. It provides capabilities across the entire surgical spectrum:</p>"},{"location":"about.html#what-is-3d-slicer","title":"What is 3D Slicer?","text":"<p>3D Slicer is an open-source software platform for medical image informatics, image processing, and 3D visualization. Built over two decades through support from the National Institutes of Health and a worldwide developer community, Slicer brings free, powerful cross-platform (Linux, MacOSX, and Windows) processing tools to physicians, researchers, and the general public.</p>"},{"location":"about.html#3d-slicer-features","title":"3D Slicer Features","text":"<p>Multi-organ: from head to toe Support for multi-modality imaging including: MRI, CT, US, nuclear medicine, and microscopy Bidirectional interface for devices</p> <p></p>"},{"location":"about.html#sources","title":"Sources","text":"<ul> <li>https://slicer.org</li> <li>https://www.slicer.org/wiki/Main_Page</li> <li>Fedorov A., Beichel R., Kalpathy-Cramer J., Finet J., Fillion-Robin J-C., Pujol S., Bauer C., Jennings D., Fennessy F., Sonka M., Buatti J., Aylward S.R., Miller J.V., Pieper S., Kikinis R. <code>3D Slicer as an Image Computing Platform for the Quantitative Imaging Network &lt;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3466397/&gt;</code>_. Magnetic Resonance Imaging. 2012 Nov;30(9):1323-41. PMID: 22770690.</li> </ul>"},{"location":"installation.html","title":"Installation","text":""},{"location":"installation.html#requirements","title":"Requirements","text":""},{"location":"installation.html#3d-slicer","title":"3D Slicer","text":"<p>Install 3D Slicer Version 4.11.0 (or later) by downloading it from the 3D Slicer website.</p>"},{"location":"installation.html#trajectoryguide-source-code","title":"trajectoryGuide source code","text":"<p>Download the trajectoryGuide source code from GitHub. Unzip the folder and store it somewhere on your system.</p>"},{"location":"installation.html#template-space-directory","title":"Template space directory","text":"<p>Download the template space zip file from the most recent GitHub release. Unzip the folder and move it into the trajectoryGuide folder at the location <code>resources/ext_libs/space</code>. h</p>"},{"location":"installation.html#3d-slicer-setup","title":"3D Slicer setup","text":""},{"location":"installation.html#install-python-libraries","title":"Install Python libraries","text":"<ol> <li> <p>You will first need to install a few Python libraries before loading trajectoryGuide. Click the Blue and Yellow Python button located in the top menu to the right.</p> <p> Python interactor button. </p> </li> <li> <p>The Python interactor should now be visible at the bottom of the 3D Slicer window.</p> <p> 3D Slicer Python interactor. </p> </li> <li> <p>Copy and paste the command below into the Python interactor box, press <code>Enter</code> to run the command.</p> <pre><code>pip_install('--upgrade pip')\n</code></pre> </li> <li> <p>Copy and paste the command below into the Python interactor box, press <code>Enter</code> to run the command.</p> <pre><code>pip_install('scikit-image scikit-learn pandas scipy==1.5.4')\n</code></pre> </li> </ol>"},{"location":"installation.html#install-modules","title":"Install modules","text":"<p> trajectoryGuide uses the Volume Reslice Driver module from SlicerIGT. To install this use the Extension Manager module within 3D Slicer or download the source code for your slicer version here (select Slicer version --&gt; extensions --&gt; SlicerIGT).</p>"},{"location":"installation.html#add-trajectoryguide-modules","title":"Add trajectoryGuide modules","text":"<p>Note</p> <p>You will only need to add the following modules:  \u2003\u2003\u2611 dataImport  \u2003\u2003\u2611 frameDetect  \u2003\u2003\u2611 registration  \u2003\u2003\u2611 anatomicalLandmarks  \u2003\u2003\u2611 preopPlanning  \u2003\u2003\u2611 intraopPlanning  \u2003\u2003\u2611 postopProgramming  \u2003\u2003\u2611 postopLocalization  \u2003\u2003\u2611 dataView </p> <ol> <li> <p>In the top menu, click on the <code>Edit</code> menu and select <code>Application settings</code></p> <p> 3D Slicer Edit menu. </p> </li> <li> <p>In the settings dialog window select <code>Modules</code>, click the right-facing arrows next to the box with the text <code>Additional module paths</code> and click <code>Add</code></p> </li> <li> <p>Navigate to where you stored the source code for trajectoryGuide, select each of the sub-folders listed in the Note box above and click <code>Choose</code>. You will need to add each folder one-by-one.</p> <p> 3D Slicer add module path. </p> </li> <li> <p>3D Slicer will want to restart at this point, click <code>Yes</code></p> <p> 3D Slicer restart notification. </p> </li> <li> <p>Now when 3D Slicer restarts, trajectoryGuide will be included in Slicer's modules menu.</p> </li> </ol> <p> </p>"},{"location":"manuals.html","title":"Product Manuals","text":""},{"location":"manuals.html#electrophysiology","title":"Electrophysiology","text":""},{"location":"manuals.html#alpha-omega","title":"Alpha Omega","text":"<ul> <li>MapFile converter v5.1.8</li> <li>Neuro Omega medical v1.4.2</li> <li>Neuro Omega research v1.1</li> <li>Neuro Omega sdk v1.3</li> <li>Alpha Lab SnR manual v2.0.4.1</li> <li>Alpha Omega Medical Accessories Catalogue 2016</li> </ul>"},{"location":"manuals.html#medtronic-leadpoint","title":"Medtronic - Leadpoint","text":"<ul> <li>Leapoint Clinical and Technical manual 2001</li> <li>Leapoint User Guide 2003</li> <li>Leapoint Channels Amplifier Box 2003</li> <li>MicroTargeting Drive User Guide 2004</li> <li>MicroTargeting Accessories 2004</li> <li>MicroTargeting Adaptations 2003</li> </ul>"},{"location":"manuals.html#neuromodulation-devices","title":"Neuromodulation Devices","text":""},{"location":"manuals.html#medtronic","title":"Medtronic","text":"<ul> <li>SenSight lead B33005/B33015 implant manual 2021</li> <li>SenSight lead orientation card 2021</li> <li>Activa programming manual 2020</li> <li>Activa PC implant manual 2019</li> <li>Activa PC implant manual 2010</li> <li>Activa RC implant manual 2019</li> <li>Activa RC implant manual 2010</li> <li>DBS lead 3387/3389 implant manual 2019</li> <li>DBS lead 3387/3389 implant manual 2008</li> <li>Extension kit implant manual 2019</li> <li>Extension kit implant manual 2002</li> <li>Kinetra manual 2003</li> </ul>"},{"location":"manuals.html#boston-scientific","title":"Boston Scientific","text":"<ul> <li>DBS Reference guide 2019</li> <li>Vercise leads 2018</li> <li>Vercise Adapter 2018</li> <li>Vercise PC IPG 2018</li> <li>Vercise Gevia IPG 2018</li> <li>Vercise programming manual 2019</li> <li>Vercise patient controller 3 2018</li> <li>GuideXT manual v2.0.2</li> </ul>"},{"location":"manuals.html#neuronavigation","title":"Neuronavigation","text":""},{"location":"manuals.html#brainlab","title":"Brainlab","text":"<ul> <li>Brainab Elements Trajectory Planning v2.5</li> <li>Brainab Cranial Navigation System v1.4</li> <li>Brainab Automatic Registration v2.5</li> <li>Brainab Lead Localization v1.1</li> <li>Brainab iPlan Stereotaxy v3.0</li> </ul>"},{"location":"manuals.html#fhc","title":"FHC","text":"<ul> <li>Waypoint Navigator manual v4.6</li> </ul>"},{"location":"manuals.html#renishaw","title":"Renishaw","text":"<ul> <li>Neuromate product brochure 2014</li> </ul>"},{"location":"manuals.html#stereotactic-systems","title":"Stereotactic Systems","text":""},{"location":"manuals.html#leksell-stereotactic-system","title":"Leksell Stereotactic System","text":"<ul> <li>User manual 1007063 Rev. 04 (2015-05)</li> </ul>"},{"location":"manuals.html#crw-stereotactic-system","title":"CRW Stereotactic System","text":"<ul> <li>CRW manual 2010</li> <li>CRW product catalog 2017</li> <li>CRW product catalog 2009</li> </ul>"},{"location":"manuals.html#mri","title":"MRI","text":""},{"location":"manuals.html#clinical","title":"Clinical","text":"<ul> <li>2021 LHSC DBS pre-op - GE 1.5T</li> <li>2018 LHSC DBS pre-op - GE 1.5T</li> <li>2018 LHSC DBS post-op - GE 1.5T</li> </ul>"},{"location":"manuals.html#cfmm-research","title":"CFMM Research","text":"<ul> <li>2024 CFMM DBS pre-op - Siemens 7T</li> <li>CFMM DBS pre-op - Siemens 3T</li> <li>2021 CFMM Epilepsy pre-op - Siemens 7T</li> </ul>"},{"location":"manuals.html#other-electrodes","title":"Other Electrodes","text":""},{"location":"manuals.html#alcis-neuro","title":"ALCIS Neuro","text":"<ul> <li>Product catalog 2021</li> </ul>"},{"location":"manuals.html#neuropace","title":"NeuroPace","text":"<ul> <li>Product catalog 2019</li> <li>Electrode Dimensions</li> </ul>"},{"location":"manuals.html#pmt","title":"PMT","text":"<ul> <li>Product catalog 2015</li> <li>sEEG product catalog 2014</li> </ul>"},{"location":"manuals.html#st-jude","title":"St Jude","text":"<ul> <li>Product manual 2017</li> </ul>"},{"location":"3dslicer/01_interface.html","title":"3D Slicer Interface","text":"<p>Warning</p> <p>Ensure you are using 3D Slicer 4.11</p>"},{"location":"3dslicer/01_interface.html#interface-overview","title":"Interface Overview","text":"<p>\u2003\u2003Slicer stores all loaded data in a data repository, called the \u201cscene\u201d (or Slicer scene or MRML scene). Each data set, such as an image volume, surface model, or point set, is represented in the scene as a \u201cnode\u201d.</p> <p>\u2003\u2003Slicer provides a large number \u201cmodules\u201d, each implementing a specific set of functions for creating or manipulating data in the scene. Modules typically do not interact with each other directly: they just all operate on the data nodes in the scene. Slicer package contains over 100 built-in modules and additional modules can be installed by using the Extension Manager.</p> <p></p>"},{"location":"3dslicer/01_interface.html#2d-views","title":"2D Views","text":"<p>\u2003\u2003Three default slice views are provided (with Red, Yellow and Green colored bars) in which Axial, Saggital, Coronal or Oblique 2D slices of volume images can be displayed. Additional generic slice views have a grey colored bar and an identifying number in their upper left corner.</p> <p></p> <p>\u2003\u2003Slice View Controls: The colored bar across any Slice View shows a pushpin icon on its left. When the mouse rolls over this icon, a panel for configuring the slice view is displayed. The panel is hidden when the mouse moves away. For persistent display of this panel, just click the pushpin icon. For more options, click the double-arrow icon.</p> <p>View Controllers module provides an alternate way of displaying these controllers in the Module Panel.</p> <ul> <li>Reset field of view (small square) centers the slice on the current background volume</li> <li>Link button synchronizes properties (which volumes are displayed, zoom factor, position of parallel views, opacities, etc.) between all slice views in the same view group. Long-click on the button exposes hot-linked option, which controls when properties are synchronized (immediately or when the mouse button is released).</li> <li>Eye button in the top row can show the current slice in 3D views. Drop-down menu of the button contains advanced options to customize how this slice is rendered: \"...match volume\" means that the properties are taken from the full volume, while \"...match 2D\" means that the properties are copied from the current slice view (for example, copies zoom and pan position). Typically these differences are subtle and the settings can be left at default.</li> <li>Orientation Selection displays allows you to choose the orientation for this slice view.</li> <li>Lightbox to select a mosiac (a.k.a. contact sheet) view.  Not all operations work in this mode and it may be removed in the future.</li> <li>Reformat allows interactive manipulation of the slice orientation.</li> <li>Blending options how foreground and background layers are mixed.</li> <li>Spacing and Field of View Spacing defines the increment for the slice offset slider.  Field of view sets the zoom level for the slice.</li> <li>Rotate to Volume Plane changes the orientation of the slice to match the closest acquisition orientation of the displayed volume</li> <li>Show Orientation Marker controls display of human, cube, etc in lower right corner</li> <li>Ruler controls display of ruler in slice view</li> </ul>"},{"location":"3dslicer/01_interface.html#3d-view","title":"3D View","text":"<p>Displays a rendered 3D view of the scene along with visual references to specify orientation and scale. Default orientation axes:</p> <ul> <li>A = anterior; P = posterior</li> <li>R = right; L = left</li> <li>S = superior; I = inferior</li> </ul> <p></p> <p>3D View Controls: The blue bar across any 3D View shows a pushpin icon on its left. When the mouse rolls over this icon, a panel for configuring the 3D View is displayed. The panel is hidden when the mouse moves away. For persistent display of this panel, just click the pushpin icon.</p>"},{"location":"3dslicer/01_interface.html#mouse-keyboard-shortcuts","title":"Mouse &amp; Keyboard Shortcuts","text":"<p>The following summary of shortcuts is taken from the 3D Slicer documentation. </p> <p>Note</p> <p>The shortcuts are working on any stable 3D Slicer version &gt;=4.10.0</p>"},{"location":"3dslicer/01_interface.html#generic-shortcuts","title":"Generic shortcuts","text":"<p> Shortcut Operation <code>Ctrl</code> + <code>f</code> find module by name (hit <code>Enter</code> to select) <code>Ctrl</code> + <code>a</code> add data from file <code>Ctrl</code> + <code>o</code> add data from file <code>Ctrl</code> + <code>s</code> save data to files <code>Ctrl</code> + <code>w</code> close scene <code>Ctrl</code> + <code>0</code> show Error Log <code>Ctrl</code> + <code>1</code> show Application Help <code>Ctrl</code> + <code>2</code> show Application Settings <code>Ctrl</code> + <code>3</code> show/hide Python Interactor <code>Ctrl</code> + <code>4</code> show Extension Manager <code>Ctrl</code> + <code>5</code> show/hide Module Panel <code>Ctrl</code> + <code>h</code> open default startup module (configurable in Application Settings) <p></p>"},{"location":"3dslicer/01_interface.html#2d-views_1","title":"2D Views","text":"<p>\u2003\u2003The following shortcuts are available when a slice view is active. To activate a view, click inside the view: if you do not want to change anything in the view, just activate it then do <code>right-click</code> without moving the mouse. Note that simply hovering over the mouse over a slice view will not activate the view.</p> <p> Shortcut Operation <code>right-click</code> + <code>drag up/down</code> zoom image in/out <code>left-click</code> + <code>drag up/down</code> adjust level of image <code>left-click</code> + <code>drag left/right</code> adjust window of image <code>Ctrl</code> + <code>mouse wheel</code> zoom image in/out <code>middle-click</code> + <code>drag</code> pan (translate) view <code>Shift</code> + <code>left-click</code> + <code>drag</code> pan (translate) view <code>left arrow</code> / <code>right arrow</code> move to previous/next slice <code>b</code> / <code>f</code> move to previous/next slice <code>Shift</code> + <code>mouse move</code> move crosshair in all views <code>v</code> toggle slice visibility in 3D view <code>r</code> reset zoom and pan to default <code>g</code> toggle segmentation or labelmap volume <code>t</code> toggle foreground volume visibility <code>[</code> / <code>]</code> use previous/next volume as background <code>{</code> / <code>}</code> use previous/next volume as foreground <p></p>"},{"location":"3dslicer/01_interface.html#3d-views","title":"3D views","text":"<p>\u2003\u2003The following shortcuts are available when a 3D view is active. To activate a view, click inside the view: if you do not want to change anything in the view, just activate it then do <code>right-click</code> without moving the mouse. Note that simply hovering over the mouse over a slice view will not activate the view.</p> <p> Shortcut Operation <code>Shift</code> + <code>mouse move</code> move crosshair in all views <code>left-click</code> + <code>drag</code> rotate view <code>left arrow</code> / <code>right arrow</code> rotate view <code>up arrow</code> / <code>down arrow</code> rotate view <code>End</code> or <code>Keypad 1</code> rotate to view from anterior <code>Shift</code> + <code>End</code> or <code>Shift</code> + <code>Keypad 1</code> rotate to view from posterior <code>Page Down</code> or <code>Keypad 3</code> rotate to view from left side <code>Shift</code> + <code>Page Down</code> or <code>Shift</code> + <code>Keypad 3</code> rotate to view from right side <code>Home</code> or <code>Keypad 7</code> rotate to view from superior <code>Shift</code> + <code>Home</code> or <code>Shift</code> + <code>Keypad 7</code> rotate to view from inferior <code>right-click</code> + <code>drag up/down</code> zoom view in/out <code>Ctrl</code> + <code>mouse wheel</code> zoom view in/out <code>+</code> / <code>-</code> zoom view in/out <code>middle-click</code> + <code>drag</code> pan (translate) view <code>Shift</code> + <code>left-click</code> + <code>drag</code> pan (translate) view <code>Shift</code> + <code>left arrow</code> / <code>Shift</code> + <code>right arrow</code> pan (translate) view <code>Shift</code> + <code>up arrow</code> / <code>Shift</code> + <code>down arrow</code> pan (translate) view <code>Shift</code> + <code>Keypad 2</code> / <code>Shift</code> + <code>Keypad 4</code> pan (translate) view <code>Shift</code> + <code>Keypad 6</code> / <code>Shift</code> + <code>Keypad 8</code> pan (translate) view <code>Keypad 0</code> or <code>Insert</code> reset zoom and pan, rotate to nearest standard view <p></p>"},{"location":"3dslicer/02_saving_data.html","title":"Saving Slicer Scenes","text":"<p>Warning</p> <p>Ensure you are using 3D Slicer 4.11</p>"},{"location":"3dslicer/02_saving_data.html#walkthrough","title":"Walkthrough","text":"<ol> <li> <p>Click on the File menu at the top.</p> <p> 3D Slicer file menu. </p> </li> <li> <p>Choose Save, the dialog box shown below will appear:</p> <p> 3D Slicer file menu. </p> </li> <li> <p>If this is your first time saving you will have to define the directory to save the files. Click on Change directory for selected files. The dialog box below will appear:</p> <p> 3D Slicer file menu. </p> </li> <li> <p>Find the directory where you want to save the data, create a new folder called [VolumeID]_scene and then double click on it so you are now within the directory. Select Choose.</p> </li> <li> <p>You will now notice that the .nii file is de-selected and is in the original directory location. All the other files you will be saving are in the newly created [VolumeID]_scene folder. Click Save.</p> <p> 3D Slicer file menu. </p> </li> <li> <p>If this not your first time saving you will see two warning messages. The first will notify you that the .mrml file already exists and ask if you want to replace it. Click OK.</p> <p> 3D Slicer file menu. </p> </li> <li> <p>A second warning message will appear letting you know that the .fcsv file already exists and ask if you would like to replace it. Click Yes to All. This will overwrite your old datafiles with the newer ones.</p> <p> 3D Slicer file menu. </p> </li> <li> <p>To close the current scene, before opening a new subject, click the File menu and select Close Scene.</p> <p> 3D Slicer file menu. </p> </li> </ol> <p> </p>"},{"location":"widgets/00_overview.html","title":"Overview","text":""},{"location":"widgets/00_overview.html#neuronavigation","title":"Neuronavigation","text":"<p>\u2003\u2003The main goal of image guidance in neurosurgery is to accurately project magnetic resonance imaging (MRI) and/or computed tomography (CT) data into the operative field for defining anatomical landmarks, pathological structures and margins of tumors. To achieve this, \"neuronavigation\" software solutions have been developed to provide precise spatial information to neurosurgeons. Safe and accurate navigation of brain anatomy is of great importance when attempting to avoid important structures such as arteries and nerves.</p> <p>\u2003\u2003Neuronavigation software provides orientation information to the surgeon during all three phases of surgery: 1) pre-operative trajectory planning, 2) the intraoperative stereotactic procedure, and 3) post-operative visualization. Trajectory planning is performed prior to surgery using preoperative MRI data. On the day of surgery, the plans are transferred to stereotactic space using a frame or frame-less system. In both instances, a set of radiopaque fiducials are detected, providing the transformation matrix from anatomical space to stereotactic space. During the surgical procedure, the plans are updated according to intraoperative data collected (i.e. microelectrode recordings, electrode stimulation etc.). After the surgery, post-operative MRI or CT imaging confirms the actual position of the trajectory(ies).</p>"},{"location":"widgets/00_overview.html#trajectoryguide","title":"trajectoryGuide","text":"<p> trajectoryGuide is an open-source software suite that provides the capability to plan neurosurgical trajectories within 3D Slicer. trajectoryGuide contains several modules that span the three phases of surgical intervention: pre-op, intra-op, and post-op.</p>"},{"location":"widgets/00_overview.html#prior-art","title":"Prior Art","text":""},{"location":"widgets/00_overview.html#open-source","title":"Open source","text":""},{"location":"widgets/00_overview.html#pydbs","title":"PyDBS","text":"<p>Developed by Pierre Jannin. The software is not freely available, a description of the tool can be found in this publication.</p>"},{"location":"widgets/00_overview.html#tactics","title":"Tactics","text":"<p>Developed by David G. Gobbi and Yves P.Starreveld. The software is available on GitHub.</p>"},{"location":"widgets/00_overview.html#ogles2","title":"Ogles2","text":"<p>Developed by Johannes A. Koeppen and based on Ogle written by Dr. Michael J Gourlay. The software can be downloaded from Sourceforge or the Neuranse website.</p>"},{"location":"widgets/00_overview.html#commercial-software","title":"Commercial software","text":""},{"location":"widgets/00_overview.html#stealthstation-s8","title":"StealthStation S8","text":"<p>Developed by Medtronic. More information can be found on their website.</p>"},{"location":"widgets/00_overview.html#neuroinspire","title":"Neuroinspire","text":"<p>Developed by Renishaw. More information can be found on their website.</p>"},{"location":"widgets/00_overview.html#elements","title":"Elements","text":"<p>Developed by Brainlab. More information can be found on their website.</p>"},{"location":"widgets/00_overview.html#inomed-planning-system","title":"Inomed Planning System","text":"<p>Developed by Inomed. More information can be found on their website.</p>"},{"location":"widgets/00_overview.html#waypoint-navigator","title":"WayPoint Navigator","text":"<p>Distributed by FHC. More information can be found on their website.</p>"},{"location":"widgets/00_overview.html#mnps","title":"MNPS","text":"<p>Developed by Mevis. More information can be found on their website.</p>"},{"location":"widgets/00_overview.html#neurosight","title":"NeuroSight","text":"<p>Developed by Integra. More information can be found on their website.</p>"},{"location":"widgets/00_overview.html#claronav-navient","title":"ClaroNav Navient","text":"<p>Developed by ClaroNav. More information can be found on their website.</p> <p> </p>"},{"location":"widgets/01_data_import.html","title":"Data Import","text":"<p>Warning</p> <p>If you have not installed trajectoryGuide into 3D Slicer please follow the installation instructions.</p> <p>\u2003\u2003The first module in trajectoryGuide handles the import of patient imaging data. The data should be within a single directory, this directory will be selected within the import window (do not select the files within the directory). During the initial data import for a patient, trajectoryGuide will store a copy of the imaging data into a <code>source</code> directory as a backup, these files will remain unchanged.</p> <p> trajectoryGuide stores all imaging data in NIFTI (Neuroinformatics Technology Initiative) format, with the file extension <code>.nii.gz</code>. If the original imaging data is in DICOM format, the files will first need to be converted to NIFTI according to BIDS (see section above).</p>"},{"location":"widgets/01_data_import.html#data-directory","title":"Data directory","text":""},{"location":"widgets/01_data_import.html#input-directory-structure","title":"Input directory structure","text":"<p> trajectoryGuide requires the input data folder to be organized according to Brain Imaging Data Structure (BIDS). The following is an example input directory.</p> <pre><code>bids/\n    \u251c\u2500\u2500 dataset_description.json\n    \u2514\u2500\u2500 sub-&lt;subject_label&gt;/\n        \u2514\u2500\u2500 ses-&lt;ses_label&gt;/\n            \u251c\u2500\u2500 anat/\n            \u2502   \u251c\u2500\u2500 sub-&lt;subject_label&gt;_ses-&lt;ses_label&gt;_T1w.nii.gz\n            \u2502   \u251c\u2500\u2500 sub-&lt;subject_label&gt;_ses-&lt;ses_label&gt;_PD.nii.gz\n            \u2502   \u2514\u2500\u2500 sub-&lt;subject_label&gt;_ses-&lt;ses_label&gt;_acq-Tra_T2w.nii.gz\n            \u2514\u2500\u2500 ct/\n                \u2514\u2500\u2500 sub-&lt;subject_label&gt;_ses-&lt;ses_label&gt;_acq-Frame_ct.nii.gz\n</code></pre>"},{"location":"widgets/01_data_import.html#output-directory-structure","title":"Output directory structure","text":"<p> trajectoryGuide trajectoryGuide stores processed data within the derivatives directoy of the BIDS dataset.</p> <pre><code>bids/\n    \u251c\u2500\u2500 dataset_description.json\n    \u2514\u2500\u2500 sub-&lt;subject_label&gt;/...\nderivatives/\n    \u2514\u2500\u2500 trajectoryGuide/\n        \u2514\u2500\u2500 sub-&lt;subject_label&gt;/\n                \u251c\u2500\u2500 sub-&lt;subject_label&gt;_surgical_data.json\n                \u251c\u2500\u2500 sub-&lt;subject_label&gt;_T1w.nii.gz\n                \u251c\u2500\u2500 sub-&lt;subject_label&gt;_T1w.json\n                \u251c\u2500\u2500 sub-&lt;subject_label&gt;_space-T1w_acq-Tra_T2w.nii.gz\n                \u251c\u2500\u2500 sub-&lt;subject_label&gt;_space-T1w_acq-Tra_T2w.json\n                \u251c\u2500\u2500 sub-&lt;subject_label&gt;_desc-rigid_from-TraT2w_to-T1w_xfm.h5\n                \u251c\u2500\u2500 sub-&lt;subject_label&gt;_space-T1w_PD.nii.gz\n                \u251c\u2500\u2500 sub-&lt;subject_label&gt;_space-T1w_PD.json\n                \u251c\u2500\u2500 sub-&lt;subject_label&gt;_desc-rigid_from-PD_to-T1w_xfm.h5\n                \u251c\u2500\u2500 sub-&lt;subject_label&gt;_ses-pre_coordsystem.json\n                \u251c\u2500\u2500 settings/...\n                \u251c\u2500\u2500 source/...\n                \u251c\u2500\u2500 space/...\n                \u2514\u2500\u2500 summaries/...\n</code></pre> <p>\u2003\u2003Each image volume has an associated <code>.json</code> file that stores metadata associated with the volume as it progresses through the trajectoryGuide workflow. Select the import options prior to loading the patient directory.</p> <p> Data import module in trajectoryGuide. </p> <ul> <li>Rename Scans: trajectoryGuide will rename the imaging data to comply with BIDS format, the imaging filenames will be shortened</li> <li>Use Previous Values: this option is recommended. If the patient directory has already been loaded by trajectoryGuide, then the previous data values will be re-loaded</li> <li>BIDSify data: future feature to convert DICOM data to BIDS.</li> </ul> <p> </p>"},{"location":"widgets/04_frame_detection.html","title":"Frame Detection","text":"<p>Note</p> <p>To navigate through the 2D view: Move crosshairs in all views: hold <code>Shift</code> while moving the mouse Zoom in/out: hold the <code>right</code> mouse button while moving mouse up/down (can hold <code>Control/Command</code> and scroll) Pan (translate) scan: hold <code>middle-mouse button</code> while moving the mouse</p>"},{"location":"widgets/04_frame_detection.html#automatic-frame-detection","title":"Automatic frame detection","text":"<p>\u2003\u2003Automatic frame detection will work for CT and MRI. From the drop-down menu, next to <code>Fiducial Volume</code>, select the volume containing the stereotactic frame. Choose the stereotactic frame that is captured in the CT volume and press <code>Detect Frame Fiducials</code>. </p> <p> Frame detection widget interface. </p> <p>If the automatic detection was successful you will see an image like this:</p> <p> Frame fiducials with frame registration errors. </p> <p>\u2003\u2003Scroll up/down the slices to check the accuracy of the frame detection. The displayed numbers are the fiducial registration errors, lower values indicate a more accurate registration. Values lower than 0.5mm appear in Green, while values above 0.5mm appear in Red. On the left-hand side you will see the overall frame registration error (anything below 0.5 mm should be acceptable).</p> <p>\u2003\u2003If you are satisfied with the results, select Confirm Frame Fiducials. If you are not satisfied, you can try adjusting frame registration settings and re-run autodection (see ensuing section).</p>"},{"location":"widgets/04_frame_detection.html#adjust-frame-registration-settings","title":"Adjust frame registration settings","text":"<p>You can modify the default frame registration settings by clicking the Advanced Settings box in the frame detection widget.</p> <p> Frame detection advanced settings. </p> <ul> <li>Transform type (default: Rigidbody): Rigidbody, Similarity, Affine.</li> <li>Iterations (default: 100): Set the maximum number of iterations.</li> <li>Max Landmarks (default: 200): Set the maximum number of frame fiducials to use, each slice in the CT scan contains a set of fiducial points. For instance, if a CT scan is acquired with 124 slices, using a Leksell frame, there would be ~ 600 fiducial points.</li> <li>Match Centroids (default: No): Starts the process by translating source centroid to target centroid.</li> <li>Reverse Source/Target (default: No): Will invert the transform so the source is fixed and the target is floating. This is helpful if the target has fewer data samples than the source.</li> <li>Target Point Radius (default: 0.5 mm): Radius to use for the target frame fiducials.</li> <li>Mean Distance Measure (Default: RMS): metric to use when measuring the point registration error.</li> </ul>"},{"location":"widgets/04_frame_detection.html#troubleshooting-automatic-frame-detection","title":"Troubleshooting automatic frame detection","text":"<p>\u2003\u2003The first parameter to adjust would be Match Centroids, select Yes. A pop-up message will appear asking if you want to overwrite the previous frame registration data, select Yes:</p> <p> Frame detection pop-up message. </p> <p>\u2003\u2003If you are still not happy with the registration, try increasing the number of iterations to 200 and re-run. The other parameter you can adjust is the number of iterations, increasing the value to 300. You may also want to try decreasing the radius of the target by 0.1 mm. The last choice would be to adjust the transform type, however this will introduce some non-linearity into the registration.</p>"},{"location":"widgets/04_frame_detection.html#manual-frame-detection","title":"Manual frame detection","text":"<p>\u2003\u2003To run manual frame detection select the button Manual Detection. You will need to identify each frame fiducial one-by-one on the same axial slice. If you are unsure of how the stereotactic frame fiducials are numbered you can press <code>Frame Fiducial Legend</code> to see the mapping. All point fiducials will need to be placed on the same axial slice. When you are finished, press Confirm Frame Fiducials.</p> <p> Manual frame detection fiducials. </p>"},{"location":"widgets/04_frame_detection.html#supported-frame-systems","title":"Supported Frame Systems","text":""},{"location":"widgets/04_frame_detection.html#leksell-frame-localizer","title":"Leksell frame localizer","text":"<p> Leksell stereotactic system. </p>"},{"location":"widgets/04_frame_detection.html#brw-frame-localizer","title":"BRW frame localizer","text":"<p> BRW stereotactic system. </p>"},{"location":"widgets/04_frame_detection.html#crw-frame","title":"CRW frame","text":"<p> CRW stereotactic system. </p>"},{"location":"widgets/04_frame_detection.html#automatic-frame-detection-algorithm","title":"Automatic frame detection algorithm","text":"<p>\u2003\u2003The automatic frame detection algorithm first employs an intensity threshold to identify pixel clusters that may belong to an N-localizer. After the entire image volume is scanned, the identified clusters are either accepted or rejected based on the stereotactic frame geometry. The intensity threshold is a binary threshold that results in pixel values less than a specified intensity value to be removed (i.e. brain tissue will be removed). For the Leksell and CRW frame systems, a morphological erosion step is applied to the threshold image followed by a morphological dilation. Erosion of a binary image sharpens the boundaries of foreground pixels, which will act to make features in the image volume \u201cthinner\u201d. The resulting image will contain frame and skull artifact but the frame fiducial markers will no longer be present. To finalize the image mask, a morphological dilation step is applied to the eroded image to enlarge the remaining structures in the image. Since the frame fiducial markers were removed with the erosion step, the objects being enlarged are left-over artifact to be removed - which forms the final image mask. The image mask is inverted and intersected with the threshold image to recover the fiducial markers.</p> <p>\u2003\u2003The resulting masked image is processed further to obtain connected components (i.e. neighbouring pixels that share the same value). As long as neighbouring pixels share the same value, they will be labelled as a single region. All connected regions are assigned the same integer value to form clusters of connected pixels. Since the dimensions of the N-localizer are known the expected pixel cluster size can be estimated.</p>"},{"location":"widgets/04_frame_detection.html#leksell-localization-sample","title":"Leksell localization sample","text":""},{"location":"widgets/04_frame_detection.html#brw-localization-sample","title":"BRW localization sample","text":""},{"location":"widgets/04_frame_detection.html#crw-localization-sample","title":"CRW localization sample","text":""},{"location":"widgets/05_registration.html","title":"Registration","text":""},{"location":"widgets/05_registration.html#patient-space-registration","title":"Patient Space Registration","text":"<p>\u2003\u2003All registrations with patient scans will be rigid registrations. With some of the more advanced algorithms you can override this and run non-linear registration but it is strongly discouraged. See the below Algorithms to learn more about each algorithm and the respective settings.</p> <p> Patient space registration settings. </p>"},{"location":"widgets/05_registration.html#registration-settings","title":"Registration Settings","text":"<ul> <li>Reference Volume: the scan that all other scans will be registered to (generally the pre-operative T1w scan).</li> <li>Frame Volume: the scan that contains the sterotactic frame (either MRI or CT).</li> <li>Floating volumes: the scans that will be co-registered to the reference volume. You can un-check any scans you do not want registered, all scans checked in this drop-down box will be registered.</li> </ul> <p>\u2003\u2003Within the Reference Volume drop-down box, select the scan you want to co-register all other scans to (Reference). In the Frame Volume drop-down box, select the scan that contains the stereotactic fiducials. In the Floating Volumes drop-down box, all other scans (floating) will be checked to indicate they will be registered to the reference. If there are any floating scans you do not want registered, uncheck them.</p> <p> Patient space drop-down volume boxes. </p> <p>\u2003\u2003To begin the registration, press the Run Registration button. The Registration Process box will display updated information during the registration. When the registration is complete, the view will be automatically changed to a compare view.</p> <p> Patient space drop-down volume boxes. </p>"},{"location":"widgets/05_registration.html#check-registration-results","title":"Check Registration Results","text":"<p>\u2003\u2003For each registration you will either select Confirm Registration or Decline Registration. If you choose to decline a registration, the registration can be re-run with a different algorithm. To check the registration, it is helpful to use the opacity slider to change the opacity of the foreground scan (floating scan).</p> <p> Patient space drop-down volume boxes. </p> <p>\u2003\u2003You can also use the Layer Reveal tool to check the registration in more detail. This tool displays a square that contains half the foreground scan and half the background scan.</p> <p> Registration layer reveal tool. </p> <p>\u2003\u2003When finished checking the registrations, any confirmed registered scans will disappear from the Floating Volumes drop-down box, declined scans will still appear in the drop-down box. To re-run the registration, update any settings and press the Run Registration button, all previous registration information, for the current floating scans, will be erased.</p>"},{"location":"widgets/05_registration.html#algorithms","title":"Algorithms","text":"<p>\u2003\u2003The default algorithm will be NiftyReg using nearest neighbor interpolation when applying the transform. You are able to change the registration algorithm and parameters according to the following information.</p>"},{"location":"widgets/05_registration.html#niftyreg-reg_aladin","title":"NiftyReg - reg_aladin","text":"<p>For information about this algorithm you can visit this page.</p> <ul> <li>interpolation order: nearest neighbor, cubic, sinc, linear (default nearest neighbor)</li> </ul>"},{"location":"widgets/05_registration.html#ants-antsregistrationsynquick","title":"ANTS - antsRegistrationSyNQuick","text":"<ul> <li>transform type: rigid, rigid+affine, rigid+affine+syn, rigid+syn, rigid+affine+b-spl syn, rigid+b-spl syn<ul> <li>rigid: rigid (1 stage)</li> <li>rigid+affine: rigid + affine (2 stages)</li> <li>rigid+affine+syn: rigid + affine + deformable syn (3 stages)</li> <li>rigid+syn: rigid + deformable syn (2 stages)</li> <li>rigid+affine+b-spl syn: rigid + affine + deformable b-spline syn (3 stages)</li> <li>rigid+b-spl syn: rigid + deformable b-spline syn (2 stages)</li> </ul> </li> <li>threads: number of threads to use</li> <li>cc radius: histogram bins for mutual information in SyN stage (default = 32)</li> <li>spline distance: spline distance for deformable B-spline SyN transform (default = 26)</li> <li>histogram matching: use histogram matching (default = 0)</li> </ul>"},{"location":"widgets/05_registration.html#fsl-flirt","title":"FSL - flirt","text":"<p>For information about this algorithm you can visit this page.</p> <ul> <li>interpolation order: nearest neighbor, spline, sinc, trilinear (default trilinear)</li> <li>cost: used during the second stage. Options are: mutual info, correlation ratio, least square, normalized correlation, normalized mutual info (default corratio)</li> <li>search cost: used during initial search stage. Options are: mutual info, correlation ratio, least square, normalized correlation, normalized mutual info (default corratio)</li> <li>coarse search: search delta angle to use during initial alignment between the images (default 60)</li> <li>fine search:  search delta angle to use during final alignment between the images (default 18)</li> </ul>"},{"location":"widgets/05_registration.html#ants-antsregistration","title":"ANTS - antsRegistration","text":"<p>\u2003\u2003For information about this algorithm you can visit this page. This algorithm gives the user more control over each step. The user can specify the \"stages\" of registration, where a stage consists of a transform and an image metric. Each stage consists of levels with specific values set for iterations, shrink factors, and smoothing sigmas.</p> <ul> <li>interpolation: applied only to the output image. Options are: linear, nearest neighbor, bspline, cosinc, hammingsinc  (default nearest neighbor)</li> <li>metric: CC,MI,GC   (CC)<ul> <li>CC: ANTS neighborhood cross correlation</li> <li>MI: Mutual information</li> <li>GC: Global Correlation</li> </ul> </li> <li>gradient step: how big the mutual info, correlation ratio, least square, normalized correlation, normalized mutual info  (default 0.1)</li> <li>convergence: for each hierarchical step, this value specifies the threshold that is needed to be met before stopping the respective step  (default 1000x500x250x100x0,1e-6,10)</li> <li>shrink: shrink factor for each hierarchical step  (default 8x4x2x2x1)<ul> <li>i.e. for an image with 256x256x256 voxels, the levels will work on images of size 32mm, 64mm, 128mm, and 256mm</li> </ul> </li> <li>smoothing: smoothing factor applied in each hierarchical step  (default 3x2x1x0x0vox)</li> </ul>"},{"location":"widgets/05_registration.html#template-space-registration","title":"Template Space Registration","text":"<p>\u2003\u2003Click <code>Run Registration</code>. The registration progression will be updated within the <code>Registration Progress</code> window. Once registration is completed, you will see the co-registered volumes appear in the floating drop-down box (under <code>Co-registered Volumes</code>). You will now confirm that the registration results by clicking the <code>Compare Volumes</code> button. For each registration you will either select <code>Confirm Registration</code> or <code>Decline Registration</code>. If you choose to decline a registration, you will be able to re-run the registration with a different algorithm.</p> <p> </p>"},{"location":"widgets/06_anatomical_fiducials.html","title":"Registration","text":"<p>Note</p> <p>To navigate through the 2D view: Move crosshairs in all views: hold <code>Shift</code> while moving the mouse Zoom in/out: hold the <code>right</code> mouse button while moving mouse up/down (can hold <code>Control/Command</code> and scroll) Pan (translate) scan: hold <code>middle-mouse button</code> while moving the mouse</p>"},{"location":"widgets/06_anatomical_fiducials.html#placing-fiducials","title":"Placing Fiducials","text":"<p>\u2003\u2003The midline plane will need to be determined, which relies on four points: the anterior commissure (AC), the posterior commissure (PC), and two midline points (Mid 1-2). The midline points should be at least one interhemispheric point and one brainstem point (see section below for landmark positions). These 4 points are then used to define the midline plane, which is used to define the Talaraich coordinate system.</p> <p>\u2003\u2003To place a fiducial point, click on the place point button () and drop the point at the indicated landmark. Once you have placed AC, PC and at least 2 midlines, click Confirm Fiducials. A new entry will be added to the fiducial table for the point <code>MCP</code>.</p> <p> \u2192 </p> <p>Warning</p> <p>If you modify any fiducial points you will need to press Confirm Fiducials again to re-calculate <code>MCP</code></p>"},{"location":"widgets/06_anatomical_fiducials.html#anatomical-landmarks","title":"Anatomical Landmarks","text":""},{"location":"widgets/06_anatomical_fiducials.html#ac-point","title":"AC point","text":"<p> The anterior commissure. </p>"},{"location":"widgets/06_anatomical_fiducials.html#pc-point","title":"PC point","text":"<p> The posterior commissure. </p>"},{"location":"widgets/06_anatomical_fiducials.html#midline-points","title":"Midline Points","text":""},{"location":"widgets/06_anatomical_fiducials.html#genu","title":"Genu","text":"<p> Genu. </p>"},{"location":"widgets/06_anatomical_fiducials.html#infracollicular-sulcus","title":"Infracollicular Sulcus","text":"<p> The infracollicular sulcus. </p>"},{"location":"widgets/06_anatomical_fiducials.html#superior-interpeduncular-fossa","title":"Superior interpeduncular fossa","text":"<p> The superior interpeduncular fossa. </p> <p> </p>"},{"location":"widgets/07_preoperative_planning.html","title":"Preoperative Planning","text":"<p>Note</p> <p>To navigate through the 2D view: Move crosshairs in all views: hold <code>Shift</code> while moving the mouse Zoom in/out: hold the <code>right</code> mouse button while moving mouse up/down (can hold <code>Control/Command</code> and scroll) Pan (translate) scan: hold <code>middle-mouse button</code> while moving the mouse</p>"},{"location":"widgets/07_preoperative_planning.html#addingmodifying-a-plan","title":"Adding/Modifying a Plan","text":"<p>\u2003\u2003The planning module contains two coordinate groupboxes, one for ACPC space and the other for stereotactic space. The coordinates are linked to the position of the crosshairs, when the crosshairs move the coordinates are updated in real-time.</p> <p> The preop planning module. </p> <p> trajectoryGuide links objects and data in the scene to the plan name. When you switch between plans, the values in the coordinate boxes will update to the current plan values. Before setting a target/entry, you will need to add a new plan. Click <code>Add</code> in the Plan Name groupbox and set a name for the current plan. Defining the entry/target point is similar to the previous Anatomical fiducials widget except you can also enter exact coordinate values into the ACPC/Stereotactic space coordinate boxes and press \"Update Crosshairs\" to move the crosshairs to the specified coordinates.</p> <p>Warning</p> <ul> <li>Only enter stereotactic based coordinates into the stereotactic coordinate boxes</li> <li>Only enter ACPC based coordinates into the ACPC space boxes</li> </ul>"},{"location":"widgets/09_postoperative_localization.html","title":"Postoperative Localization","text":""},{"location":"widgets/09_postoperative_localization.html#locating-postoperative-electrode","title":"Locating postoperative electrode","text":"<p>For now, electrode localization in trajectoryGuide is achieved by manually defining the bottom and top of each electrode. The user should place the postoperative imaging volume (CT and/or MRI) inside the patient folder, re-load trajectoryGuide, and run the registration step. Once the postoperative volume is aligned with the reference image volume it can be used to locate the electrode(s).</p> <p>\u2003\u2003The user must indicate the plan that is associated with the electrode being localized. If only postoperative localization is being performed for the patient a plan name can be defined within this module. The user is then asked to place a fiducial marker at the very tip of the electrode to mark the \u201ctarget\u201d and another fiducial point near where it exists from the skull to indicate the \u201centry\u201d point. Once the two points are placed the \u201cConfirm Electrode\u201d button can be pressed and the postoperative electrode will be rendered in the 2D and 3D views.</p> <p> The postop localization module. </p>"},{"location":"widgets/10_postoperative_programming.html","title":"Volume of activated tissue","text":"<p>The volume of activated tissue (VAT) also referred to as the volume of tissue activated (VTA) is a model the predicts the extent and location of neural activation produced by stimulation. In trajectoryGuide, the model proposed by Dembek et al. (2017) has been utilized since it does not require image processing to be conducted prior to VAT computation <sup>1</sup>. The calculation of the stimulation field radius based on the DBS stimulation parameters is described the following equation:</p>  r=\\left ( \\frac{pw}{90 \\mu s} \\right )*\\sqrt{0.72\\frac{Vm}{A}*\\frac{I}{165 V/m}}  <p>\u2003\u2003where pw is the pulse width (microseconds), A is the amplitude of stimulation (voltage or milliamperes), and I is the impedance (Ohms) of the electrode contact being used for stimulation. The value 0.72 Vm is a constant validated by Dembek et al. (2017) in a previous study <sup>1</sup>. A more complex stimulation field model will eventually be incorporated into trajectoryGuide that can handle bipolar stimulation. For now, only a monopolar stimulation model can be generated. To generate the VAT models in trajectoryGuide, the user needs to input the stimulation parameters including the active contact, stimulation amplitude, frequency, pulse width, and impedance</p> <p> The postop volume of activated tissue module. </p> <p><sup>1</sup> T. A. Dembek et al., \u201cProbabilistic mapping of deep brain stimulation effects in essential tremor.,\u201d NeuroImage Clin., vol. 13, pp. 164\u2013173, 2017, doi: 10.1016/j.nicl.2016.11.019</p>"}]}