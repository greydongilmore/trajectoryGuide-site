{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"An open-source software for neurosurgical trajectory planning, visualization, and postoperative assessment What is trajectoryGuide? trajectoryGuide provides the capability to plan surgical trajectories within 3D Slicer, an open-source medical imaging software. trajectoryGuide contains modules that span the three phases of neurosurgical trajectory planning: Preoperative features \u00b6 automatic stereotactic frame detection (supported frames: Leksell, BRW, and CRW) co-registration of MRI and CT scans (incorporated registration algorithms: ANTS, FSL, or NiftyReg) trajectory planning providing coordinates in anatomical and stereotactic space (including arc, ring angles) Perioperative features \u00b6 update final electrode position based on intra-operative testing display microelectrode recordings (MER) within the patients MRI space Postoperative features \u00b6 electrode localization (using post-op imaging) visualize stimulation settings as volume of activated tissue view data within a template space (provided spaces: MNI152NLin2009bAsym, MNI152NLin2009cAsym, and PD25)","title":"Home"},{"location":"index.html#preoperative-features","text":"automatic stereotactic frame detection (supported frames: Leksell, BRW, and CRW) co-registration of MRI and CT scans (incorporated registration algorithms: ANTS, FSL, or NiftyReg) trajectory planning providing coordinates in anatomical and stereotactic space (including arc, ring angles)","title":"Preoperative features"},{"location":"index.html#perioperative-features","text":"update final electrode position based on intra-operative testing display microelectrode recordings (MER) within the patients MRI space","title":"Perioperative features"},{"location":"index.html#postoperative-features","text":"electrode localization (using post-op imaging) visualize stimulation settings as volume of activated tissue view data within a template space (provided spaces: MNI152NLin2009bAsym, MNI152NLin2009cAsym, and PD25)","title":"Postoperative features"},{"location":"about.html","text":"Neuronavigation \u00b6 The main goal of image guidance in neurosurgery is to accurately project magnetic resonance imaging (MRI) and/or computed tomography (CT) data into the operative field for defining anatomical landmarks, pathological structures and margins oftumors. To achieve this, \"neuronavigation\" software solutions have been developed to provide precise spatial information to neurosurgeons. Safe and accurate navigation of brain anatomy is of great importance when attempting to avoid important structures such as arteries and nerves. Neuronavigation software provides orientation information to the surgeon during all three phases of surgery: 1) pre-operative trajectory planning, 2) the intraoperative steroetactic procedure, and 3) post-operative visualization. Trajectory planning is performed prior to surgery using preoperative MRI data. On the day of surgery, the plans are transferred to sterotactic space using a frame or frame-less system. In both instances, a set of radiopaque fiducials are detected, providing the transformation matrix from anatomical space to sterotactic space. During the surgical procedure, the plans are updated according to intraoperative data collected (i.e. microelectrode recordings, electrode stimulation etc.). After the surgery, post-operative MRI or CT imaging confirms the actual position of the trajectory(ies). trajectoryGuide? \u00b6 trajectoryGuide is a surgical planning, visuazliation, and postoperative assessment tool used for various trajectory surguries. It provides capabilities across the entire surgical spectrum: What is 3D Slicer? \u00b6 3D Slicer is an open-source software platform for medical image informatics, image processing, and 3D visualization. Built over two decades through support from the National Institutes of Health and a worldwide developer community, Slicer brings free, powerful cross-platform (Linux, MacOSX, and Windows) processing tools to physicians, researchers, and the general public. 3D Slicer Features \u00b6 Multi-organ: from head to toe Support for multi-modality imaging including: MRI, CT, US, nuclear medicine, and microscopy Bidirectional interface for devices Sources \u00b6 https://slicer.org https://www.slicer.org/wiki/Main_Page Fedorov A., Beichel R., Kalpathy-Cramer J., Finet J., Fillion-Robin J-C., Pujol S., Bauer C., Jennings D., Fennessy F., Sonka M., Buatti J., Aylward S.R., Miller J.V., Pieper S., Kikinis R. 3D Slicer as an Image Computing Platform for the Quantitative Imaging Network <https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3466397/> _. Magnetic Resonance Imaging. 2012 Nov;30(9):1323-41. PMID: 22770690.","title":"About"},{"location":"about.html#neuronavigation","text":"The main goal of image guidance in neurosurgery is to accurately project magnetic resonance imaging (MRI) and/or computed tomography (CT) data into the operative field for defining anatomical landmarks, pathological structures and margins oftumors. To achieve this, \"neuronavigation\" software solutions have been developed to provide precise spatial information to neurosurgeons. Safe and accurate navigation of brain anatomy is of great importance when attempting to avoid important structures such as arteries and nerves. Neuronavigation software provides orientation information to the surgeon during all three phases of surgery: 1) pre-operative trajectory planning, 2) the intraoperative steroetactic procedure, and 3) post-operative visualization. Trajectory planning is performed prior to surgery using preoperative MRI data. On the day of surgery, the plans are transferred to sterotactic space using a frame or frame-less system. In both instances, a set of radiopaque fiducials are detected, providing the transformation matrix from anatomical space to sterotactic space. During the surgical procedure, the plans are updated according to intraoperative data collected (i.e. microelectrode recordings, electrode stimulation etc.). After the surgery, post-operative MRI or CT imaging confirms the actual position of the trajectory(ies).","title":"Neuronavigation"},{"location":"about.html#trajectoryguide","text":"trajectoryGuide is a surgical planning, visuazliation, and postoperative assessment tool used for various trajectory surguries. It provides capabilities across the entire surgical spectrum:","title":"trajectoryGuide?"},{"location":"about.html#what-is-3d-slicer","text":"3D Slicer is an open-source software platform for medical image informatics, image processing, and 3D visualization. Built over two decades through support from the National Institutes of Health and a worldwide developer community, Slicer brings free, powerful cross-platform (Linux, MacOSX, and Windows) processing tools to physicians, researchers, and the general public.","title":"What is 3D Slicer?"},{"location":"about.html#3d-slicer-features","text":"Multi-organ: from head to toe Support for multi-modality imaging including: MRI, CT, US, nuclear medicine, and microscopy Bidirectional interface for devices","title":"3D Slicer Features"},{"location":"about.html#sources","text":"https://slicer.org https://www.slicer.org/wiki/Main_Page Fedorov A., Beichel R., Kalpathy-Cramer J., Finet J., Fillion-Robin J-C., Pujol S., Bauer C., Jennings D., Fennessy F., Sonka M., Buatti J., Aylward S.R., Miller J.V., Pieper S., Kikinis R. 3D Slicer as an Image Computing Platform for the Quantitative Imaging Network <https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3466397/> _. Magnetic Resonance Imaging. 2012 Nov;30(9):1323-41. PMID: 22770690.","title":"Sources"},{"location":"installation.html","text":"Installation \u00b6 Requirements \u00b6 3D Slicer \u00b6 Install 3D Slicer Version 4.11.0 (or later) by downloading it from the 3D Slicer website . trajectoryGuide source code \u00b6 Download the trajectoryGuide source code from GitHub . Unzip the folder and store it somewhere on your system. Template space directory \u00b6 Download the template space zip file from the most recent GitHub release . Unzip the folder and move it into the trajectoryGuide folder at the location resources/ext_libs/space . h 3D Slicer setup \u00b6 Install Python libraries \u00b6 You will first need to install a few Python libraries before loading trajectoryGuide. Click the Blue and Yellow Python button located in the top menu to the right. Python interactor button. The Python interactor should now be visible at the bottom of the 3D Slicer window. 3D Slicer Python interactor. Copy and paste the command below into the Python interactor box, press Enter to run the command. pip_install('--upgrade pip') Copy and paste the command below into the Python interactor box, press Enter to run the command. pip_install('scikit-image scikit-learn pandas scipy==1.5.4') Install modules \u00b6 \u2003\u2003 trajectoryGuide uses the Volume Reslice Driver module from SlicerIGT . To install this use the Extension Manager module within 3D Slicer or download the source code for your slicer version here (select Slicer version --> extensions --> SlicerIGT). Add trajectoryGuide modules \u00b6 Note You will only need to add the following modules: \u2003\u2003\u2611 dataImport \u2003\u2003\u2611 frameDetect \u2003\u2003\u2611 registration \u2003\u2003\u2611 anatomicalLandmarks \u2003\u2003\u2611 preopPlanning \u2003\u2003\u2611 intraopPlanning \u2003\u2003\u2611 postopProgramming \u2003\u2003\u2611 postopLocalization \u2003\u2003\u2611 dataView In the top menu, click on the Edit menu and select Application settings 3D Slicer Edit menu. In the settings dialog window select Modules , click the right-facing arrows next to the box with the text Additional module paths and click Add Navigate to where you stored the source code for trajectoryGuide, select each of the sub-folders listed in the Note box above and click Choose . You will need to add each folder one-by-one. 3D Slicer add module path. 3D Slicer will want to restart at this point, click Yes 3D Slicer restart notification. Now when 3D Slicer restarts, trajectoryGuide will be included in Slicer's modules menu.","title":"Installation"},{"location":"installation.html#installation","text":"","title":"Installation"},{"location":"installation.html#requirements","text":"","title":"Requirements"},{"location":"installation.html#3d-slicer","text":"Install 3D Slicer Version 4.11.0 (or later) by downloading it from the 3D Slicer website .","title":"3D Slicer"},{"location":"installation.html#trajectoryguide-source-code","text":"Download the trajectoryGuide source code from GitHub . Unzip the folder and store it somewhere on your system.","title":"trajectoryGuide source code"},{"location":"installation.html#template-space-directory","text":"Download the template space zip file from the most recent GitHub release . Unzip the folder and move it into the trajectoryGuide folder at the location resources/ext_libs/space . h","title":"Template space directory"},{"location":"installation.html#3d-slicer-setup","text":"","title":"3D Slicer setup"},{"location":"installation.html#install-python-libraries","text":"You will first need to install a few Python libraries before loading trajectoryGuide. Click the Blue and Yellow Python button located in the top menu to the right. Python interactor button. The Python interactor should now be visible at the bottom of the 3D Slicer window. 3D Slicer Python interactor. Copy and paste the command below into the Python interactor box, press Enter to run the command. pip_install('--upgrade pip') Copy and paste the command below into the Python interactor box, press Enter to run the command. pip_install('scikit-image scikit-learn pandas scipy==1.5.4')","title":"Install Python libraries"},{"location":"installation.html#install-modules","text":"trajectoryGuide uses the Volume Reslice Driver module from SlicerIGT . To install this use the Extension Manager module within 3D Slicer or download the source code for your slicer version here (select Slicer version --> extensions --> SlicerIGT).","title":"Install modules"},{"location":"installation.html#add-trajectoryguide-modules","text":"Note You will only need to add the following modules: \u2003\u2003\u2611 dataImport \u2003\u2003\u2611 frameDetect \u2003\u2003\u2611 registration \u2003\u2003\u2611 anatomicalLandmarks \u2003\u2003\u2611 preopPlanning \u2003\u2003\u2611 intraopPlanning \u2003\u2003\u2611 postopProgramming \u2003\u2003\u2611 postopLocalization \u2003\u2003\u2611 dataView In the top menu, click on the Edit menu and select Application settings 3D Slicer Edit menu. In the settings dialog window select Modules , click the right-facing arrows next to the box with the text Additional module paths and click Add Navigate to where you stored the source code for trajectoryGuide, select each of the sub-folders listed in the Note box above and click Choose . You will need to add each folder one-by-one. 3D Slicer add module path. 3D Slicer will want to restart at this point, click Yes 3D Slicer restart notification. Now when 3D Slicer restarts, trajectoryGuide will be included in Slicer's modules menu.","title":"Add trajectoryGuide modules"},{"location":"manuals.html","text":"Product Manuals \u00b6 Electrophysiology \u00b6 Alpha Omega \u00b6 MapFile converter v5.1.8 Neuro Omega medical v1.4.2 Neuro Omega research v1.1 Neuro Omega sdk v1.3 Alpha Lab SnR manual v2.0.4.1 Alpha Omega Medical Accessories Catalogue 2016 Medtronic - Leadpoint \u00b6 Clinical and Technical manual 2001 Neuromodulation Devices \u00b6 Medtronic \u00b6 SenSight lead B33005/B33015 implant manual 2021 SenSight lead orientation card 2021 Activa programming manual 2020 Activa PC implant manual 2019 Activa PC implant manual 2010 Activa RC implant manual 2019 Activa RC implant manual 2010 DBS lead 3387/3389 implant manual 2019 DBS lead 3387/3389 implant manual 2008 Extension kit implant manual 2019 Extension kit implant manual 2002 Kinetra manual 2003 Boston Scientific \u00b6 DBS Reference guide 2019 Vercise leads 2018 Vercise Adapter 2018 Vercise PC IPG 2018 Vercise Gevia IPG 2018 Vercise programming manual 2019 Vercise patient controller 3 2018 GuideXT manual v2.0.2 Neuronavigation \u00b6 Brainlab \u00b6 Brainab Elements Trajectory Planning v2.5 Brainab Cranial Navigation System v1.4 Brainab Automatic Registration v2.5 Brainab Lead Localization v1.1 Brainab iPlan Stereotaxy v3.0 FHC \u00b6 Waypoint Navigator manual v4.6 Renishaw \u00b6 Neuromate product brochure 2014 Stereotactic Systems \u00b6 Leksell Stereotactic System \u00b6 User manual 1007063 Rev. 04 (2015-05) CRW Stereotactic System \u00b6 CRW manual 2010 CRW product catalog 2017 CRW product catalog 2009 MRI \u00b6 Clinical \u00b6 2021 LHSC pre-op 1.5T MRI sequences - DBS 2018 LHSC pre-op 1.5T MRI sequences - DBS 2018 LHSC post-op 1.5T MRI sequences - DBS Research \u00b6 2023 CFMM pre-op 3T MRI sequences - DBS Other Electrodes \u00b6 ALCIS Neuro \u00b6 Product catalog 2021 Neuropace \u00b6 Product catalog 2019 PMT \u00b6 Product catalog 2015 sEEG product catalog 2014 St Jude \u00b6 Product manual 2017","title":"Product Manuals"},{"location":"manuals.html#product-manuals","text":"","title":"Product Manuals"},{"location":"manuals.html#electrophysiology","text":"","title":"Electrophysiology"},{"location":"manuals.html#alpha-omega","text":"MapFile converter v5.1.8 Neuro Omega medical v1.4.2 Neuro Omega research v1.1 Neuro Omega sdk v1.3 Alpha Lab SnR manual v2.0.4.1 Alpha Omega Medical Accessories Catalogue 2016","title":"Alpha Omega"},{"location":"manuals.html#medtronic-leadpoint","text":"Clinical and Technical manual 2001","title":"Medtronic - Leadpoint"},{"location":"manuals.html#neuromodulation-devices","text":"","title":"Neuromodulation Devices"},{"location":"manuals.html#medtronic","text":"SenSight lead B33005/B33015 implant manual 2021 SenSight lead orientation card 2021 Activa programming manual 2020 Activa PC implant manual 2019 Activa PC implant manual 2010 Activa RC implant manual 2019 Activa RC implant manual 2010 DBS lead 3387/3389 implant manual 2019 DBS lead 3387/3389 implant manual 2008 Extension kit implant manual 2019 Extension kit implant manual 2002 Kinetra manual 2003","title":"Medtronic"},{"location":"manuals.html#boston-scientific","text":"DBS Reference guide 2019 Vercise leads 2018 Vercise Adapter 2018 Vercise PC IPG 2018 Vercise Gevia IPG 2018 Vercise programming manual 2019 Vercise patient controller 3 2018 GuideXT manual v2.0.2","title":"Boston Scientific"},{"location":"manuals.html#neuronavigation","text":"","title":"Neuronavigation"},{"location":"manuals.html#brainlab","text":"Brainab Elements Trajectory Planning v2.5 Brainab Cranial Navigation System v1.4 Brainab Automatic Registration v2.5 Brainab Lead Localization v1.1 Brainab iPlan Stereotaxy v3.0","title":"Brainlab"},{"location":"manuals.html#fhc","text":"Waypoint Navigator manual v4.6","title":"FHC"},{"location":"manuals.html#renishaw","text":"Neuromate product brochure 2014","title":"Renishaw"},{"location":"manuals.html#stereotactic-systems","text":"","title":"Stereotactic Systems"},{"location":"manuals.html#leksell-stereotactic-system","text":"User manual 1007063 Rev. 04 (2015-05)","title":"Leksell Stereotactic System"},{"location":"manuals.html#crw-stereotactic-system","text":"CRW manual 2010 CRW product catalog 2017 CRW product catalog 2009","title":"CRW Stereotactic System"},{"location":"manuals.html#mri","text":"","title":"MRI"},{"location":"manuals.html#clinical","text":"2021 LHSC pre-op 1.5T MRI sequences - DBS 2018 LHSC pre-op 1.5T MRI sequences - DBS 2018 LHSC post-op 1.5T MRI sequences - DBS","title":"Clinical"},{"location":"manuals.html#research","text":"2023 CFMM pre-op 3T MRI sequences - DBS","title":"Research"},{"location":"manuals.html#other-electrodes","text":"","title":"Other Electrodes"},{"location":"manuals.html#alcis-neuro","text":"Product catalog 2021","title":"ALCIS Neuro"},{"location":"manuals.html#neuropace","text":"Product catalog 2019","title":"Neuropace"},{"location":"manuals.html#pmt","text":"Product catalog 2015 sEEG product catalog 2014","title":"PMT"},{"location":"manuals.html#st-jude","text":"Product manual 2017","title":"St Jude"},{"location":"3dslicer/01_interface.html","text":"Warning Ensure you are using 3D Slicer 4.11 Interface Overview \u00b6 \u2003\u2003Slicer stores all loaded data in a data repository, called the \u201cscene\u201d (or Slicer scene or MRML scene). Each data set, such as an image volume, surface model, or point set, is represented in the scene as a \u201cnode\u201d. \u2003\u2003Slicer provides a large number \u201cmodules\u201d, each implementing a specific set of functions for creating or manipulating data in the scene. Modules typically do not interact with each other directly: they just all operate on the data nodes in the scene. Slicer package contains over 100 built-in modules and additional modules can be installed by using the Extension Manager. 2D Views \u00b6 \u2003\u2003Three default slice views are provided (with Red, Yellow and Green colored bars) in which Axial, Saggital, Coronal or Oblique 2D slices of volume images can be displayed. Additional generic slice views have a grey colored bar and an identifying number in their upper left corner. \u2003\u2003Slice View Controls: The colored bar across any Slice View shows a pushpin icon on its left. When the mouse rolls over this icon, a panel for configuring the slice view is displayed. The panel is hidden when the mouse moves away. For persistent display of this panel, just click the pushpin icon. For more options, click the double-arrow icon. View Controllers module provides an alternate way of displaying these controllers in the Module Panel. Reset field of view (small square) centers the slice on the current background volume Link button synchronizes properties (which volumes are displayed, zoom factor, position of parallel views, opacities, etc.) between all slice views in the same view group. Long-click on the button exposes hot-linked option, which controls when properties are synchronized (immediately or when the mouse button is released). Eye button in the top row can show the current slice in 3D views. Drop-down menu of the button contains advanced options to customize how this slice is rendered: \"...match volume\" means that the properties are taken from the full volume, while \"...match 2D\" means that the properties are copied from the current slice view (for example, copies zoom and pan position). Typically these differences are subtle and the settings can be left at default. Orientation Selection displays allows you to choose the orientation for this slice view. Lightbox to select a mosiac (a.k.a. contact sheet) view. Not all operations work in this mode and it may be removed in the future. Reformat allows interactive manipulation of the slice orientation. Blending options how foreground and background layers are mixed. Spacing and Field of View Spacing defines the increment for the slice offset slider. Field of view sets the zoom level for the slice. Rotate to Volume Plane changes the orientation of the slice to match the closest acquisition orientation of the displayed volume Show Orientation Marker controls display of human, cube, etc in lower right corner Ruler controls display of ruler in slice view 3D View \u00b6 Displays a rendered 3D view of the scene along with visual references to specify orientation and scale. Default orientation axes: A = anterior; P = posterior R = right; L = left S = superior; I = inferior 3D View Controls: The blue bar across any 3D View shows a pushpin icon on its left. When the mouse rolls over this icon, a panel for configuring the 3D View is displayed. The panel is hidden when the mouse moves away. For persistent display of this panel, just click the pushpin icon. Mouse & Keyboard Shortcuts \u00b6 The following summary of shortcuts is taken from the 3D Slicer documentation . Note The shortcuts are working on any stable 3D Slicer version >=4.10.0 Generic shortcuts \u00b6 Shortcut Operation Ctrl + f find module by name (hit Enter to select) Ctrl + a add data from file Ctrl + o add data from file Ctrl + s save data to files Ctrl + w close scene Ctrl + 0 show Error Log Ctrl + 1 show Application Help Ctrl + 2 show Application Settings Ctrl + 3 show/hide Python Interactor Ctrl + 4 show Extension Manager Ctrl + 5 show/hide Module Panel Ctrl + h open default startup module (configurable in Application Settings) 2D Views \u00b6 \u2003\u2003The following shortcuts are available when a slice view is active. To activate a view, click inside the view: if you do not want to change anything in the view, just activate it then do right-click without moving the mouse. Note that simply hovering over the mouse over a slice view will not activate the view. Shortcut Operation right-click + drag up/down zoom image in/out left-click + drag up/down adjust level of image left-click + drag left/right adjust window of image Ctrl + mouse wheel zoom image in/out middle-click + drag pan (translate) view Shift + left-click + drag pan (translate) view left arrow / right arrow move to previous/next slice b / f move to previous/next slice Shift + mouse move move crosshair in all views v toggle slice visibility in 3D view r reset zoom and pan to default g toggle segmentation or labelmap volume t toggle foreground volume visibility [ / ] use previous/next volume as background { / } use previous/next volume as foreground 3D views \u00b6 \u2003\u2003The following shortcuts are available when a 3D view is active. To activate a view, click inside the view: if you do not want to change anything in the view, just activate it then do right-click without moving the mouse. Note that simply hovering over the mouse over a slice view will not activate the view. Shortcut Operation Shift + mouse move move crosshair in all views left-click + drag rotate view left arrow / right arrow rotate view up arrow / down arrow rotate view End or Keypad 1 rotate to view from anterior Shift + End or Shift + Keypad 1 rotate to view from posterior Page Down or Keypad 3 rotate to view from left side Shift + Page Down or Shift + Keypad 3 rotate to view from right side Home or Keypad 7 rotate to view from superior Shift + Home or Shift + Keypad 7 rotate to view from inferior right-click + drag up/down zoom view in/out Ctrl + mouse wheel zoom view in/out + / - zoom view in/out middle-click + drag pan (translate) view Shift + left-click + drag pan (translate) view Shift + left arrow / Shift + right arrow pan (translate) view Shift + up arrow / Shift + down arrow pan (translate) view Shift + Keypad 2 / Shift + Keypad 4 pan (translate) view Shift + Keypad 6 / Shift + Keypad 8 pan (translate) view Keypad 0 or Insert reset zoom and pan, rotate to nearest standard view","title":"User Interface"},{"location":"3dslicer/01_interface.html#interface-overview","text":"Slicer stores all loaded data in a data repository, called the \u201cscene\u201d (or Slicer scene or MRML scene). Each data set, such as an image volume, surface model, or point set, is represented in the scene as a \u201cnode\u201d. \u2003\u2003Slicer provides a large number \u201cmodules\u201d, each implementing a specific set of functions for creating or manipulating data in the scene. Modules typically do not interact with each other directly: they just all operate on the data nodes in the scene. Slicer package contains over 100 built-in modules and additional modules can be installed by using the Extension Manager.","title":"Interface Overview"},{"location":"3dslicer/01_interface.html#2d-views","text":"Three default slice views are provided (with Red, Yellow and Green colored bars) in which Axial, Saggital, Coronal or Oblique 2D slices of volume images can be displayed. Additional generic slice views have a grey colored bar and an identifying number in their upper left corner. \u2003\u2003Slice View Controls: The colored bar across any Slice View shows a pushpin icon on its left. When the mouse rolls over this icon, a panel for configuring the slice view is displayed. The panel is hidden when the mouse moves away. For persistent display of this panel, just click the pushpin icon. For more options, click the double-arrow icon. View Controllers module provides an alternate way of displaying these controllers in the Module Panel. Reset field of view (small square) centers the slice on the current background volume Link button synchronizes properties (which volumes are displayed, zoom factor, position of parallel views, opacities, etc.) between all slice views in the same view group. Long-click on the button exposes hot-linked option, which controls when properties are synchronized (immediately or when the mouse button is released). Eye button in the top row can show the current slice in 3D views. Drop-down menu of the button contains advanced options to customize how this slice is rendered: \"...match volume\" means that the properties are taken from the full volume, while \"...match 2D\" means that the properties are copied from the current slice view (for example, copies zoom and pan position). Typically these differences are subtle and the settings can be left at default. Orientation Selection displays allows you to choose the orientation for this slice view. Lightbox to select a mosiac (a.k.a. contact sheet) view. Not all operations work in this mode and it may be removed in the future. Reformat allows interactive manipulation of the slice orientation. Blending options how foreground and background layers are mixed. Spacing and Field of View Spacing defines the increment for the slice offset slider. Field of view sets the zoom level for the slice. Rotate to Volume Plane changes the orientation of the slice to match the closest acquisition orientation of the displayed volume Show Orientation Marker controls display of human, cube, etc in lower right corner Ruler controls display of ruler in slice view","title":"2D Views"},{"location":"3dslicer/01_interface.html#3d-view","text":"Displays a rendered 3D view of the scene along with visual references to specify orientation and scale. Default orientation axes: A = anterior; P = posterior R = right; L = left S = superior; I = inferior 3D View Controls: The blue bar across any 3D View shows a pushpin icon on its left. When the mouse rolls over this icon, a panel for configuring the 3D View is displayed. The panel is hidden when the mouse moves away. For persistent display of this panel, just click the pushpin icon.","title":"3D View"},{"location":"3dslicer/01_interface.html#mouse-keyboard-shortcuts","text":"The following summary of shortcuts is taken from the 3D Slicer documentation . Note The shortcuts are working on any stable 3D Slicer version >=4.10.0","title":"Mouse &amp; Keyboard Shortcuts"},{"location":"3dslicer/01_interface.html#generic-shortcuts","text":"Shortcut Operation Ctrl + f find module by name (hit Enter to select) Ctrl + a add data from file Ctrl + o add data from file Ctrl + s save data to files Ctrl + w close scene Ctrl + 0 show Error Log Ctrl + 1 show Application Help Ctrl + 2 show Application Settings Ctrl + 3 show/hide Python Interactor Ctrl + 4 show Extension Manager Ctrl + 5 show/hide Module Panel Ctrl + h open default startup module (configurable in Application Settings)","title":"Generic shortcuts"},{"location":"3dslicer/01_interface.html#2d-views_1","text":"The following shortcuts are available when a slice view is active. To activate a view, click inside the view: if you do not want to change anything in the view, just activate it then do right-click without moving the mouse. Note that simply hovering over the mouse over a slice view will not activate the view. Shortcut Operation right-click + drag up/down zoom image in/out left-click + drag up/down adjust level of image left-click + drag left/right adjust window of image Ctrl + mouse wheel zoom image in/out middle-click + drag pan (translate) view Shift + left-click + drag pan (translate) view left arrow / right arrow move to previous/next slice b / f move to previous/next slice Shift + mouse move move crosshair in all views v toggle slice visibility in 3D view r reset zoom and pan to default g toggle segmentation or labelmap volume t toggle foreground volume visibility [ / ] use previous/next volume as background { / } use previous/next volume as foreground","title":"2D Views"},{"location":"3dslicer/01_interface.html#3d-views","text":"The following shortcuts are available when a 3D view is active. To activate a view, click inside the view: if you do not want to change anything in the view, just activate it then do right-click without moving the mouse. Note that simply hovering over the mouse over a slice view will not activate the view. Shortcut Operation Shift + mouse move move crosshair in all views left-click + drag rotate view left arrow / right arrow rotate view up arrow / down arrow rotate view End or Keypad 1 rotate to view from anterior Shift + End or Shift + Keypad 1 rotate to view from posterior Page Down or Keypad 3 rotate to view from left side Shift + Page Down or Shift + Keypad 3 rotate to view from right side Home or Keypad 7 rotate to view from superior Shift + Home or Shift + Keypad 7 rotate to view from inferior right-click + drag up/down zoom view in/out Ctrl + mouse wheel zoom view in/out + / - zoom view in/out middle-click + drag pan (translate) view Shift + left-click + drag pan (translate) view Shift + left arrow / Shift + right arrow pan (translate) view Shift + up arrow / Shift + down arrow pan (translate) view Shift + Keypad 2 / Shift + Keypad 4 pan (translate) view Shift + Keypad 6 / Shift + Keypad 8 pan (translate) view Keypad 0 or Insert reset zoom and pan, rotate to nearest standard view","title":"3D views"},{"location":"3dslicer/02_saving_data.html","text":"Warning Ensure you are using 3D Slicer 4.11 Walkthrough \u00b6 Click on the File menu at the top. 3D Slicer file menu. Choose Save , the dialog box shown below will appear: 3D Slicer file menu. If this is your first time saving you will have to define the directory to save the files. Click on Change directory for selected files . The dialog box below will appear: 3D Slicer file menu. Find the directory where you want to save the data, create a new folder called [VolumeID]_scene and then double click on it so you are now within the directory. Select Choose . You will now notice that the .nii file is de-selected and is in the original directory location. All the other files you will be saving are in the newly created [VolumeID]_scene folder. Click Save . 3D Slicer file menu. If this not your first time saving you will see two warning messages. The first will notify you that the .mrml file already exists and ask if you want to replace it. Click OK . 3D Slicer file menu. A second warning message will appear letting you know that the .fcsv file already exists and ask if you would like to replace it. Click Yes to All . This will overwrite your old datafiles with the newer ones. 3D Slicer file menu. To close the current scene, before opening a new subject, click the File menu and select Close Scene . 3D Slicer file menu.","title":"Saving Data"},{"location":"3dslicer/02_saving_data.html#walkthrough","text":"Click on the File menu at the top. 3D Slicer file menu. Choose Save , the dialog box shown below will appear: 3D Slicer file menu. If this is your first time saving you will have to define the directory to save the files. Click on Change directory for selected files . The dialog box below will appear: 3D Slicer file menu. Find the directory where you want to save the data, create a new folder called [VolumeID]_scene and then double click on it so you are now within the directory. Select Choose . You will now notice that the .nii file is de-selected and is in the original directory location. All the other files you will be saving are in the newly created [VolumeID]_scene folder. Click Save . 3D Slicer file menu. If this not your first time saving you will see two warning messages. The first will notify you that the .mrml file already exists and ask if you want to replace it. Click OK . 3D Slicer file menu. A second warning message will appear letting you know that the .fcsv file already exists and ask if you would like to replace it. Click Yes to All . This will overwrite your old datafiles with the newer ones. 3D Slicer file menu. To close the current scene, before opening a new subject, click the File menu and select Close Scene . 3D Slicer file menu.","title":"Walkthrough"},{"location":"widgets/00_overview.html","text":"Neuronavigation \u00b6 \u2003\u2003The main goal of image guidance in neurosurgery is to accurately project magnetic resonance imaging (MRI) and/or computed tomography (CT) data into the operative field for defining anatomical landmarks, pathological structures and margins of tumors. To achieve this, \"neuronavigation\" software solutions have been developed to provide precise spatial information to neurosurgeons. Safe and accurate navigation of brain anatomy is of great importance when attempting to avoid important structures such as arteries and nerves. \u2003\u2003Neuronavigation software provides orientation information to the surgeon during all three phases of surgery: 1) pre-operative trajectory planning, 2) the intraoperative stereotactic procedure, and 3) post-operative visualization. Trajectory planning is performed prior to surgery using preoperative MRI data. On the day of surgery, the plans are transferred to stereotactic space using a frame or frame-less system. In both instances, a set of radiopaque fiducials are detected, providing the transformation matrix from anatomical space to stereotactic space. During the surgical procedure, the plans are updated according to intraoperative data collected (i.e. microelectrode recordings, electrode stimulation etc.). After the surgery, post-operative MRI or CT imaging confirms the actual position of the trajectory(ies). trajectoryGuide \u00b6 \u2003\u2003 trajectoryGuide is an open-source software suite that provides the capability to plan neurosurgical trajectories within 3D Slicer. trajectoryGuide contains several modules that span the three phases of surgical intervention: pre-op, intra-op, and post-op. Prior Art \u00b6 Open source \u00b6 PyDBS \u00b6 Developed by Pierre Jannin. The software is not freely available, a description of the tool can be found in this publication . Tactics \u00b6 Developed by David G. Gobbi and Yves P.Starreveld. The software is available on GitHub . Ogles2 \u00b6 Developed by Johannes A. Koeppen and based on Ogle written by Dr. Michael J Gourlay. The software can be downloaded from Sourceforge or the Neuranse website. Commercial software \u00b6 StealthStation S8 \u00b6 Developed by Medtronic. More information can be found on their website . Neuroinspire \u00b6 Developed by Renishaw. More information can be found on their website . Elements \u00b6 Developed by Brainlab. More information can be found on their website . Inomed Planning System \u00b6 Developed by Inomed. More information can be found on their website . WayPoint Navigator \u00b6 Distributed by FHC. More information can be found on their website . MNPS \u00b6 Developed by Mevis. More information can be found on their website . NeuroSight \u00b6 Developed by Integra. More information can be found on their website . ClaroNav Navient \u00b6 Developed by ClaroNav. More information can be found on their website .","title":"Overview"},{"location":"widgets/00_overview.html#neuronavigation","text":"The main goal of image guidance in neurosurgery is to accurately project magnetic resonance imaging (MRI) and/or computed tomography (CT) data into the operative field for defining anatomical landmarks, pathological structures and margins of tumors. To achieve this, \"neuronavigation\" software solutions have been developed to provide precise spatial information to neurosurgeons. Safe and accurate navigation of brain anatomy is of great importance when attempting to avoid important structures such as arteries and nerves. \u2003\u2003Neuronavigation software provides orientation information to the surgeon during all three phases of surgery: 1) pre-operative trajectory planning, 2) the intraoperative stereotactic procedure, and 3) post-operative visualization. Trajectory planning is performed prior to surgery using preoperative MRI data. On the day of surgery, the plans are transferred to stereotactic space using a frame or frame-less system. In both instances, a set of radiopaque fiducials are detected, providing the transformation matrix from anatomical space to stereotactic space. During the surgical procedure, the plans are updated according to intraoperative data collected (i.e. microelectrode recordings, electrode stimulation etc.). After the surgery, post-operative MRI or CT imaging confirms the actual position of the trajectory(ies).","title":"Neuronavigation"},{"location":"widgets/00_overview.html#trajectoryguide","text":"trajectoryGuide is an open-source software suite that provides the capability to plan neurosurgical trajectories within 3D Slicer. trajectoryGuide contains several modules that span the three phases of surgical intervention: pre-op, intra-op, and post-op.","title":"trajectoryGuide"},{"location":"widgets/00_overview.html#prior-art","text":"","title":"Prior Art"},{"location":"widgets/00_overview.html#open-source","text":"","title":"Open source"},{"location":"widgets/00_overview.html#pydbs","text":"Developed by Pierre Jannin. The software is not freely available, a description of the tool can be found in this publication .","title":"PyDBS"},{"location":"widgets/00_overview.html#tactics","text":"Developed by David G. Gobbi and Yves P.Starreveld. The software is available on GitHub .","title":"Tactics"},{"location":"widgets/00_overview.html#ogles2","text":"Developed by Johannes A. Koeppen and based on Ogle written by Dr. Michael J Gourlay. The software can be downloaded from Sourceforge or the Neuranse website.","title":"Ogles2"},{"location":"widgets/00_overview.html#commercial-software","text":"","title":"Commercial software"},{"location":"widgets/00_overview.html#stealthstation-s8","text":"Developed by Medtronic. More information can be found on their website .","title":"StealthStation S8"},{"location":"widgets/00_overview.html#neuroinspire","text":"Developed by Renishaw. More information can be found on their website .","title":"Neuroinspire"},{"location":"widgets/00_overview.html#elements","text":"Developed by Brainlab. More information can be found on their website .","title":"Elements"},{"location":"widgets/00_overview.html#inomed-planning-system","text":"Developed by Inomed. More information can be found on their website .","title":"Inomed Planning System"},{"location":"widgets/00_overview.html#waypoint-navigator","text":"Distributed by FHC. More information can be found on their website .","title":"WayPoint Navigator"},{"location":"widgets/00_overview.html#mnps","text":"Developed by Mevis. More information can be found on their website .","title":"MNPS"},{"location":"widgets/00_overview.html#neurosight","text":"Developed by Integra. More information can be found on their website .","title":"NeuroSight"},{"location":"widgets/00_overview.html#claronav-navient","text":"Developed by ClaroNav. More information can be found on their website .","title":"ClaroNav Navient"},{"location":"widgets/01_data_import.html","text":"Warning If you have not installed trajectoryGuide into 3D Slicer please follow the installation instructions . \u2003\u2003The first module in trajectoryGuide handles the import of patient imaging data. The data should be within a single directory, this directory will be selected within the import window (do not select the files within the directory). During the initial data import for a patient, trajectoryGuide will store a copy of the imaging data into a source directory as a backup, these files will remain unchanged. \u2003\u2003 trajectoryGuide stores all imaging data in NIFTI (Neuroinformatics Technology Initiative) format, with the file extension .nii.gz . If the original imaging data is in DICOM format, the files will first need to be converted to NIFTI according to BIDS (see section above). Data directory \u00b6 Input directory structure \u00b6 \u2003\u2003 trajectoryGuide requires the input data folder to be organized according to Brain Imaging Data Structure (BIDS) . The following is an example input directory. bids/ \u251c\u2500\u2500 dataset_description.json \u2514\u2500\u2500 sub-<subject_label>/ \u2514\u2500\u2500 ses-<ses_label>/ \u251c\u2500\u2500 anat/ \u2502 \u251c\u2500\u2500 sub-<subject_label>_ses-<ses_label>_T1w.nii.gz \u2502 \u251c\u2500\u2500 sub-<subject_label>_ses-<ses_label>_PD.nii.gz \u2502 \u2514\u2500\u2500 sub-<subject_label>_ses-<ses_label>_acq-Tra_T2w.nii.gz \u2514\u2500\u2500 ct/ \u2514\u2500\u2500 sub-<subject_label>_ses-<ses_label>_acq-Frame_ct.nii.gz Output directory structure \u00b6 \u2003\u2003 trajectoryGuide trajectoryGuide stores processed data within the derivatives directoy of the BIDS dataset. bids / \u251c\u2500\u2500 dataset_description . json \u2514\u2500\u2500 sub -< subject_label >/ ... derivatives / \u2514\u2500\u2500 trajectoryGuide / \u2514\u2500\u2500 sub -< subject_label >/ \u251c\u2500\u2500 sub -< subject_label > _surgical_data . json \u251c\u2500\u2500 sub -< subject_label > _T1w . nii . gz \u251c\u2500\u2500 sub -< subject_label > _T1w . json \u251c\u2500\u2500 sub -< subject_label > _space - T1w_acq - Tra_T2w . nii . gz \u251c\u2500\u2500 sub -< subject_label > _space - T1w_acq - Tra_T2w . json \u251c\u2500\u2500 sub -< subject_label > _desc - rigid_from - TraT2w_to - T1w_xfm . h5 \u251c\u2500\u2500 sub -< subject_label > _space - T1w_PD . nii . gz \u251c\u2500\u2500 sub -< subject_label > _space - T1w_PD . json \u251c\u2500\u2500 sub -< subject_label > _desc - rigid_from - PD_to - T1w_xfm . h5 \u251c\u2500\u2500 sub -< subject_label > _ses - pre_coordsystem . json \u251c\u2500\u2500 settings / ... \u251c\u2500\u2500 source / ... \u251c\u2500\u2500 space / ... \u2514\u2500\u2500 summaries / ... \u2003\u2003Each image volume has an associated .json file that stores metadata associated with the volume as it progresses through the trajectoryGuide workflow. Select the import options prior to loading the patient directory. Data import module in trajectoryGuide. Rename Scans: trajectoryGuide will rename the imaging data to comply with BIDS format, the imaging filenames will be shortened Use Previous Values: this option is recommended. If the patient directory has already been loaded by trajectoryGuide, then the previous data values will be re-loaded BIDSify data: future feature to convert DICOM data to BIDS.","title":"Data Import"},{"location":"widgets/01_data_import.html#data-directory","text":"","title":"Data directory"},{"location":"widgets/01_data_import.html#input-directory-structure","text":"trajectoryGuide requires the input data folder to be organized according to Brain Imaging Data Structure (BIDS) . The following is an example input directory. bids/ \u251c\u2500\u2500 dataset_description.json \u2514\u2500\u2500 sub-<subject_label>/ \u2514\u2500\u2500 ses-<ses_label>/ \u251c\u2500\u2500 anat/ \u2502 \u251c\u2500\u2500 sub-<subject_label>_ses-<ses_label>_T1w.nii.gz \u2502 \u251c\u2500\u2500 sub-<subject_label>_ses-<ses_label>_PD.nii.gz \u2502 \u2514\u2500\u2500 sub-<subject_label>_ses-<ses_label>_acq-Tra_T2w.nii.gz \u2514\u2500\u2500 ct/ \u2514\u2500\u2500 sub-<subject_label>_ses-<ses_label>_acq-Frame_ct.nii.gz","title":"Input directory structure"},{"location":"widgets/01_data_import.html#output-directory-structure","text":"trajectoryGuide trajectoryGuide stores processed data within the derivatives directoy of the BIDS dataset. bids / \u251c\u2500\u2500 dataset_description . json \u2514\u2500\u2500 sub -< subject_label >/ ... derivatives / \u2514\u2500\u2500 trajectoryGuide / \u2514\u2500\u2500 sub -< subject_label >/ \u251c\u2500\u2500 sub -< subject_label > _surgical_data . json \u251c\u2500\u2500 sub -< subject_label > _T1w . nii . gz \u251c\u2500\u2500 sub -< subject_label > _T1w . json \u251c\u2500\u2500 sub -< subject_label > _space - T1w_acq - Tra_T2w . nii . gz \u251c\u2500\u2500 sub -< subject_label > _space - T1w_acq - Tra_T2w . json \u251c\u2500\u2500 sub -< subject_label > _desc - rigid_from - TraT2w_to - T1w_xfm . h5 \u251c\u2500\u2500 sub -< subject_label > _space - T1w_PD . nii . gz \u251c\u2500\u2500 sub -< subject_label > _space - T1w_PD . json \u251c\u2500\u2500 sub -< subject_label > _desc - rigid_from - PD_to - T1w_xfm . h5 \u251c\u2500\u2500 sub -< subject_label > _ses - pre_coordsystem . json \u251c\u2500\u2500 settings / ... \u251c\u2500\u2500 source / ... \u251c\u2500\u2500 space / ... \u2514\u2500\u2500 summaries / ... \u2003\u2003Each image volume has an associated .json file that stores metadata associated with the volume as it progresses through the trajectoryGuide workflow. Select the import options prior to loading the patient directory. Data import module in trajectoryGuide. Rename Scans: trajectoryGuide will rename the imaging data to comply with BIDS format, the imaging filenames will be shortened Use Previous Values: this option is recommended. If the patient directory has already been loaded by trajectoryGuide, then the previous data values will be re-loaded BIDSify data: future feature to convert DICOM data to BIDS.","title":"Output directory structure"},{"location":"widgets/04_frame_detection.html","text":"Note To navigate through the 2D view: Move crosshairs in all views : hold Shift while moving the mouse Zoom in/out : hold the right mouse button while moving mouse up/down (can hold Control/Command and scroll) Pan (translate) scan : hold middle-mouse button while moving the mouse Automatic frame detection \u00b6 \u2003\u2003Automatic frame detection will work for CT and MRI. From the drop-down menu, next to Fiducial Volume , select the volume containing the stereotactic frame. Choose the stereotactic frame that is captured in the CT volume and press Detect Frame Fiducials . Frame detection widget interface. If the automatic detection was successful you will see an image like this: Frame fiducials with frame registration errors. \u2003\u2003Scroll up/down the slices to check the accuracy of the frame detection. The displayed numbers are the fiducial registration errors, lower values indicate a more accurate registration. Values lower than 0.5mm appear in Green , while values above 0.5mm appear in Red . On the left-hand side you will see the overall frame registration error (anything below 0.5 mm should be acceptable). \u2003\u2003If you are satisfied with the results, select Confirm Frame Fiducials . If you are not satisfied, you can try adjusting frame registration settings and re-run autodection (see ensuing section). Adjust frame registration settings \u00b6 You can modify the default frame registration settings by clicking the Advanced Settings box in the frame detection widget. Frame detection advanced settings. Transform type (default: Rigidbody): Rigidbody, Similarity, Affine. Iterations (default: 100): Set the maximum number of iterations. Max Landmarks (default: 200): Set the maximum number of frame fiducials to use, each slice in the CT scan contains a set of fiducial points. For instance, if a CT scan is acquired with 124 slices, using a Leksell frame, there would be ~ 600 fiducial points. Match Centroids (default: No): Starts the process by translating source centroid to target centroid. Reverse Source/Target (default: No): Will invert the transform so the source is fixed and the target is floating. This is helpful if the target has fewer data samples than the source. Target Point Radius (default: 0.5 mm): Radius to use for the target frame fiducials. Mean Distance Measure (Default: RMS): metric to use when measuring the point registration error. Troubleshooting automatic frame detection \u00b6 \u2003\u2003The first parameter to adjust would be Match Centroids , select Yes . A pop-up message will appear asking if you want to overwrite the previous frame registration data, select Yes : Frame detection pop-up message. \u2003\u2003If you are still not happy with the registration, try increasing the number of iterations to 200 and re-run. The other parameter you can adjust is the number of iterations, increasing the value to 300. You may also want to try decreasing the radius of the target by 0.1 mm. The last choice would be to adjust the transform type, however this will introduce some non-linearity into the registration. Manual frame detection \u00b6 \u2003\u2003To run manual frame detection select the button Manual Detection . You will need to identify each frame fiducial one-by-one on the same axial slice. If you are unsure of how the stereotactic frame fiducials are numbered you can press Frame Fiducial Legend to see the mapping. All point fiducials will need to be placed on the same axial slice. When you are finished, press Confirm Frame Fiducials . Manual frame detection fiducials. Supported Frame Systems \u00b6 Leksell frame localizer \u00b6 Leksell stereotactic system. BRW frame localizer \u00b6 BRW stereotactic system. CRW frame \u00b6 CRW stereotactic system. Automatic frame detection algorithm \u00b6 \u2003\u2003The automatic frame detection algorithm first employs an intensity threshold to identify pixel clusters that may belong to an N-localizer. After the entire image volume is scanned, the identified clusters are either accepted or rejected based on the stereotactic frame geometry. The intensity threshold is a binary threshold that results in pixel values less than a specified intensity value to be removed (i.e. brain tissue will be removed). For the Leksell and CRW frame systems, a morphological erosion step is applied to the threshold image followed by a morphological dilation. Erosion of a binary image sharpens the boundaries of foreground pixels, which will act to make features in the image volume \u201cthinner\u201d. The resulting image will contain frame and skull artifact but the frame fiducial markers will no longer be present. To finalize the image mask, a morphological dilation step is applied to the eroded image to enlarge the remaining structures in the image. Since the frame fiducial markers were removed with the erosion step, the objects being enlarged are left-over artifact to be removed - which forms the final image mask. The image mask is inverted and intersected with the threshold image to recover the fiducial markers. \u2003\u2003The resulting masked image is processed further to obtain connected components (i.e. neighbouring pixels that share the same value). As long as neighbouring pixels share the same value, they will be labelled as a single region. All connected regions are assigned the same integer value to form clusters of connected pixels. Since the dimensions of the N-localizer are known the expected pixel cluster size can be estimated. Leksell localization sample \u00b6 BRW localization sample \u00b6 CRW localization sample \u00b6","title":"Frame Detection"},{"location":"widgets/04_frame_detection.html#automatic-frame-detection","text":"Automatic frame detection will work for CT and MRI. From the drop-down menu, next to Fiducial Volume , select the volume containing the stereotactic frame. Choose the stereotactic frame that is captured in the CT volume and press Detect Frame Fiducials . Frame detection widget interface. If the automatic detection was successful you will see an image like this: Frame fiducials with frame registration errors. \u2003\u2003Scroll up/down the slices to check the accuracy of the frame detection. The displayed numbers are the fiducial registration errors, lower values indicate a more accurate registration. Values lower than 0.5mm appear in Green , while values above 0.5mm appear in Red . On the left-hand side you will see the overall frame registration error (anything below 0.5 mm should be acceptable). \u2003\u2003If you are satisfied with the results, select Confirm Frame Fiducials . If you are not satisfied, you can try adjusting frame registration settings and re-run autodection (see ensuing section).","title":"Automatic frame detection"},{"location":"widgets/04_frame_detection.html#adjust-frame-registration-settings","text":"You can modify the default frame registration settings by clicking the Advanced Settings box in the frame detection widget. Frame detection advanced settings. Transform type (default: Rigidbody): Rigidbody, Similarity, Affine. Iterations (default: 100): Set the maximum number of iterations. Max Landmarks (default: 200): Set the maximum number of frame fiducials to use, each slice in the CT scan contains a set of fiducial points. For instance, if a CT scan is acquired with 124 slices, using a Leksell frame, there would be ~ 600 fiducial points. Match Centroids (default: No): Starts the process by translating source centroid to target centroid. Reverse Source/Target (default: No): Will invert the transform so the source is fixed and the target is floating. This is helpful if the target has fewer data samples than the source. Target Point Radius (default: 0.5 mm): Radius to use for the target frame fiducials. Mean Distance Measure (Default: RMS): metric to use when measuring the point registration error.","title":"Adjust frame registration settings"},{"location":"widgets/04_frame_detection.html#troubleshooting-automatic-frame-detection","text":"The first parameter to adjust would be Match Centroids , select Yes . A pop-up message will appear asking if you want to overwrite the previous frame registration data, select Yes : Frame detection pop-up message. \u2003\u2003If you are still not happy with the registration, try increasing the number of iterations to 200 and re-run. The other parameter you can adjust is the number of iterations, increasing the value to 300. You may also want to try decreasing the radius of the target by 0.1 mm. The last choice would be to adjust the transform type, however this will introduce some non-linearity into the registration.","title":"Troubleshooting automatic frame detection"},{"location":"widgets/04_frame_detection.html#manual-frame-detection","text":"To run manual frame detection select the button Manual Detection . You will need to identify each frame fiducial one-by-one on the same axial slice. If you are unsure of how the stereotactic frame fiducials are numbered you can press Frame Fiducial Legend to see the mapping. All point fiducials will need to be placed on the same axial slice. When you are finished, press Confirm Frame Fiducials . Manual frame detection fiducials.","title":"Manual frame detection"},{"location":"widgets/04_frame_detection.html#supported-frame-systems","text":"","title":"Supported Frame Systems"},{"location":"widgets/04_frame_detection.html#leksell-frame-localizer","text":"Leksell stereotactic system.","title":"Leksell frame localizer"},{"location":"widgets/04_frame_detection.html#brw-frame-localizer","text":"BRW stereotactic system.","title":"BRW frame localizer"},{"location":"widgets/04_frame_detection.html#crw-frame","text":"CRW stereotactic system.","title":"CRW frame"},{"location":"widgets/04_frame_detection.html#automatic-frame-detection-algorithm","text":"The automatic frame detection algorithm first employs an intensity threshold to identify pixel clusters that may belong to an N-localizer. After the entire image volume is scanned, the identified clusters are either accepted or rejected based on the stereotactic frame geometry. The intensity threshold is a binary threshold that results in pixel values less than a specified intensity value to be removed (i.e. brain tissue will be removed). For the Leksell and CRW frame systems, a morphological erosion step is applied to the threshold image followed by a morphological dilation. Erosion of a binary image sharpens the boundaries of foreground pixels, which will act to make features in the image volume \u201cthinner\u201d. The resulting image will contain frame and skull artifact but the frame fiducial markers will no longer be present. To finalize the image mask, a morphological dilation step is applied to the eroded image to enlarge the remaining structures in the image. Since the frame fiducial markers were removed with the erosion step, the objects being enlarged are left-over artifact to be removed - which forms the final image mask. The image mask is inverted and intersected with the threshold image to recover the fiducial markers. \u2003\u2003The resulting masked image is processed further to obtain connected components (i.e. neighbouring pixels that share the same value). As long as neighbouring pixels share the same value, they will be labelled as a single region. All connected regions are assigned the same integer value to form clusters of connected pixels. Since the dimensions of the N-localizer are known the expected pixel cluster size can be estimated.","title":"Automatic frame detection algorithm"},{"location":"widgets/04_frame_detection.html#leksell-localization-sample","text":"","title":"Leksell localization sample"},{"location":"widgets/04_frame_detection.html#brw-localization-sample","text":"","title":"BRW localization sample"},{"location":"widgets/04_frame_detection.html#crw-localization-sample","text":"","title":"CRW localization sample"},{"location":"widgets/05_registration.html","text":"Patient Space Registration \u00b6 \u2003\u2003All registrations with patient scans will be rigid registrations. With some of the more advanced algorithms you can override this and run non-linear registration but it is strongly discouraged. See the below Algorithms to learn more about each algorithm and the respective settings. Patient space registration settings. Registration Settings \u00b6 Reference Volume: the scan that all other scans will be registered to (generally the pre-operative T1w scan). Frame Volume: the scan that contains the sterotactic frame (either MRI or CT). Floating volumes: the scans that will be co-registered to the reference volume. You can un-check any scans you do not want registered, all scans checked in this drop-down box will be registered. \u2003\u2003Within the Reference Volume drop-down box, select the scan you want to co-register all other scans to (Reference). In the Frame Volume drop-down box, select the scan that contains the stereotactic fiducials. In the Floating Volumes drop-down box, all other scans (floating) will be checked to indicate they will be registered to the reference. If there are any floating scans you do not want registered, uncheck them. Patient space drop-down volume boxes. \u2003\u2003To begin the registration, press the Run Registration button. The Registration Process box will display updated information during the registration. When the registration is complete, the view will be automatically changed to a compare view. Patient space drop-down volume boxes. Check Registration Results \u00b6 \u2003\u2003For each registration you will either select Confirm Registration or Decline Registration . If you choose to decline a registration, the registration can be re-run with a different algorithm. To check the registration, it is helpful to use the opacity slider to change the opacity of the foreground scan (floating scan). Patient space drop-down volume boxes. \u2003\u2003You can also use the Layer Reveal tool to check the registration in more detail. This tool displays a square that contains half the foreground scan and half the background scan. Registration layer reveal tool. \u2003\u2003When finished checking the registrations, any confirmed registered scans will disappear from the Floating Volumes drop-down box, declined scans will still appear in the drop-down box. To re-run the registration, update any settings and press the Run Registration button, all previous registration information, for the current floating scans, will be erased. Algorithms \u00b6 \u2003\u2003The default algorithm will be NiftyReg using nearest neighbor interpolation when applying the transform. You are able to change the registration algorithm and parameters according to the following information. NiftyReg - reg_aladin \u00b6 For information about this algorithm you can visit this page . interpolation order: nearest neighbor, cubic, sinc, linear (default nearest neighbor) ANTS - antsRegistrationSyNQuick \u00b6 transform type: rigid, rigid+affine, rigid+affine+syn, rigid+syn, rigid+affine+b-spl syn, rigid+b-spl syn rigid: rigid (1 stage) rigid+affine: rigid + affine (2 stages) rigid+affine+syn: rigid + affine + deformable syn (3 stages) rigid+syn: rigid + deformable syn (2 stages) rigid+affine+b-spl syn: rigid + affine + deformable b-spline syn (3 stages) rigid+b-spl syn: rigid + deformable b-spline syn (2 stages) threads: number of threads to use cc radius: histogram bins for mutual information in SyN stage (default = 32) spline distance: spline distance for deformable B-spline SyN transform (default = 26) histogram matching: use histogram matching (default = 0) FSL - flirt \u00b6 For information about this algorithm you can visit this page . interpolation order: nearest neighbor, spline, sinc, trilinear (default trilinear) cost: used during the second stage. Options are: mutual info, correlation ratio, least square, normalized correlation, normalized mutual info (default corratio) search cost: used during initial search stage. Options are: mutual info, correlation ratio, least square, normalized correlation, normalized mutual info (default corratio) coarse search: search delta angle to use during initial alignment between the images (default 60) fine search: search delta angle to use during final alignment between the images (default 18) ANTS - antsRegistration \u00b6 \u2003\u2003For information about this algorithm you can visit this page . This algorithm gives the user more control over each step. The user can specify the \"stages\" of registration, where a stage consists of a transform and an image metric. Each stage consists of levels with specific values set for iterations, shrink factors, and smoothing sigmas. interpolation: applied only to the output image. Options are: linear, nearest neighbor, bspline, cosinc, hammingsinc (default nearest neighbor) metric: CC,MI,GC (CC) CC: ANTS neighborhood cross correlation MI: Mutual information GC: Global Correlation gradient step: how big the mutual info, correlation ratio, least square, normalized correlation, normalized mutual info (default 0.1) convergence: for each hierarchical step, this value specifies the threshold that is needed to be met before stopping the respective step (default 1000x500x250x100x0,1e-6,10) shrink: shrink factor for each hierarchical step (default 8x4x2x2x1) i.e. for an image with 256x256x256 voxels, the levels will work on images of size 32mm, 64mm, 128mm, and 256mm smoothing: smoothing factor applied in each hierarchical step (default 3x2x1x0x0vox) Template Space Registration \u00b6 \u2003\u2003Click Run Registration . The registration progression will be updated within the Registration Progress window. Once registration is completed, you will see the co-registered volumes appear in the floating drop-down box (under Co-registered Volumes ). You will now confirm that the registration results by clicking the Compare Volumes button. For each registration you will either select Confirm Registration or Decline Registration . If you choose to decline a registration, you will be able to re-run the registration with a different algorithm.","title":"Registration"},{"location":"widgets/05_registration.html#patient-space-registration","text":"All registrations with patient scans will be rigid registrations. With some of the more advanced algorithms you can override this and run non-linear registration but it is strongly discouraged. See the below Algorithms to learn more about each algorithm and the respective settings. Patient space registration settings.","title":"Patient Space Registration"},{"location":"widgets/05_registration.html#registration-settings","text":"Reference Volume: the scan that all other scans will be registered to (generally the pre-operative T1w scan). Frame Volume: the scan that contains the sterotactic frame (either MRI or CT). Floating volumes: the scans that will be co-registered to the reference volume. You can un-check any scans you do not want registered, all scans checked in this drop-down box will be registered. \u2003\u2003Within the Reference Volume drop-down box, select the scan you want to co-register all other scans to (Reference). In the Frame Volume drop-down box, select the scan that contains the stereotactic fiducials. In the Floating Volumes drop-down box, all other scans (floating) will be checked to indicate they will be registered to the reference. If there are any floating scans you do not want registered, uncheck them. Patient space drop-down volume boxes. \u2003\u2003To begin the registration, press the Run Registration button. The Registration Process box will display updated information during the registration. When the registration is complete, the view will be automatically changed to a compare view. Patient space drop-down volume boxes.","title":"Registration Settings"},{"location":"widgets/05_registration.html#check-registration-results","text":"For each registration you will either select Confirm Registration or Decline Registration . If you choose to decline a registration, the registration can be re-run with a different algorithm. To check the registration, it is helpful to use the opacity slider to change the opacity of the foreground scan (floating scan). Patient space drop-down volume boxes. \u2003\u2003You can also use the Layer Reveal tool to check the registration in more detail. This tool displays a square that contains half the foreground scan and half the background scan. Registration layer reveal tool. \u2003\u2003When finished checking the registrations, any confirmed registered scans will disappear from the Floating Volumes drop-down box, declined scans will still appear in the drop-down box. To re-run the registration, update any settings and press the Run Registration button, all previous registration information, for the current floating scans, will be erased.","title":"Check Registration Results"},{"location":"widgets/05_registration.html#algorithms","text":"The default algorithm will be NiftyReg using nearest neighbor interpolation when applying the transform. You are able to change the registration algorithm and parameters according to the following information.","title":"Algorithms"},{"location":"widgets/05_registration.html#niftyreg-reg_aladin","text":"For information about this algorithm you can visit this page . interpolation order: nearest neighbor, cubic, sinc, linear (default nearest neighbor)","title":"NiftyReg - reg_aladin"},{"location":"widgets/05_registration.html#ants-antsregistrationsynquick","text":"transform type: rigid, rigid+affine, rigid+affine+syn, rigid+syn, rigid+affine+b-spl syn, rigid+b-spl syn rigid: rigid (1 stage) rigid+affine: rigid + affine (2 stages) rigid+affine+syn: rigid + affine + deformable syn (3 stages) rigid+syn: rigid + deformable syn (2 stages) rigid+affine+b-spl syn: rigid + affine + deformable b-spline syn (3 stages) rigid+b-spl syn: rigid + deformable b-spline syn (2 stages) threads: number of threads to use cc radius: histogram bins for mutual information in SyN stage (default = 32) spline distance: spline distance for deformable B-spline SyN transform (default = 26) histogram matching: use histogram matching (default = 0)","title":"ANTS - antsRegistrationSyNQuick"},{"location":"widgets/05_registration.html#fsl-flirt","text":"For information about this algorithm you can visit this page . interpolation order: nearest neighbor, spline, sinc, trilinear (default trilinear) cost: used during the second stage. Options are: mutual info, correlation ratio, least square, normalized correlation, normalized mutual info (default corratio) search cost: used during initial search stage. Options are: mutual info, correlation ratio, least square, normalized correlation, normalized mutual info (default corratio) coarse search: search delta angle to use during initial alignment between the images (default 60) fine search: search delta angle to use during final alignment between the images (default 18)","title":"FSL - flirt"},{"location":"widgets/05_registration.html#ants-antsregistration","text":"For information about this algorithm you can visit this page . This algorithm gives the user more control over each step. The user can specify the \"stages\" of registration, where a stage consists of a transform and an image metric. Each stage consists of levels with specific values set for iterations, shrink factors, and smoothing sigmas. interpolation: applied only to the output image. Options are: linear, nearest neighbor, bspline, cosinc, hammingsinc (default nearest neighbor) metric: CC,MI,GC (CC) CC: ANTS neighborhood cross correlation MI: Mutual information GC: Global Correlation gradient step: how big the mutual info, correlation ratio, least square, normalized correlation, normalized mutual info (default 0.1) convergence: for each hierarchical step, this value specifies the threshold that is needed to be met before stopping the respective step (default 1000x500x250x100x0,1e-6,10) shrink: shrink factor for each hierarchical step (default 8x4x2x2x1) i.e. for an image with 256x256x256 voxels, the levels will work on images of size 32mm, 64mm, 128mm, and 256mm smoothing: smoothing factor applied in each hierarchical step (default 3x2x1x0x0vox)","title":"ANTS - antsRegistration"},{"location":"widgets/05_registration.html#template-space-registration","text":"Click Run Registration . The registration progression will be updated within the Registration Progress window. Once registration is completed, you will see the co-registered volumes appear in the floating drop-down box (under Co-registered Volumes ). You will now confirm that the registration results by clicking the Compare Volumes button. For each registration you will either select Confirm Registration or Decline Registration . If you choose to decline a registration, you will be able to re-run the registration with a different algorithm.","title":"Template Space Registration"},{"location":"widgets/06_anatomical_fiducials.html","text":"Note To navigate through the 2D view: Move crosshairs in all views : hold Shift while moving the mouse Zoom in/out : hold the right mouse button while moving mouse up/down (can hold Control/Command and scroll) Pan (translate) scan : hold middle-mouse button while moving the mouse Placing Fiducials \u00b6 \u2003\u2003The midline plane will need to be determined, which relies on four points: the anterior commissure (AC), the posterior commissure (PC), and two midline points (Mid 1-2). The midline points should be at least one interhemispheric point and one brainstem point (see section below for landmark positions). These 4 points are then used to define the midline plane, which is used to define the Talaraich coordinate system. \u2003\u2003To place a fiducial point, click on the place point button ( ) and drop the point at the indicated landmark. Once you have placed AC, PC and at least 2 midlines, click Confirm Fiducials . A new entry will be added to the fiducial table for the point MCP . \u2192 Warning If you modify any fiducial points you will need to press Confirm Fiducials again to re-calculate MCP Anatomical Landmarks \u00b6 AC point \u00b6 The anterior commissure. PC point \u00b6 The posterior commissure. Midline Points \u00b6 Genu \u00b6 Genu. Infracollicular Sulcus \u00b6 The infracollicular sulcus. Superior interpeduncular fossa \u00b6 The superior interpeduncular fossa.","title":"Anatomical Fiducials"},{"location":"widgets/06_anatomical_fiducials.html#placing-fiducials","text":"The midline plane will need to be determined, which relies on four points: the anterior commissure (AC), the posterior commissure (PC), and two midline points (Mid 1-2). The midline points should be at least one interhemispheric point and one brainstem point (see section below for landmark positions). These 4 points are then used to define the midline plane, which is used to define the Talaraich coordinate system. \u2003\u2003To place a fiducial point, click on the place point button ( ) and drop the point at the indicated landmark. Once you have placed AC, PC and at least 2 midlines, click Confirm Fiducials . A new entry will be added to the fiducial table for the point MCP . \u2192 Warning If you modify any fiducial points you will need to press Confirm Fiducials again to re-calculate MCP","title":"Placing Fiducials"},{"location":"widgets/06_anatomical_fiducials.html#anatomical-landmarks","text":"","title":"Anatomical Landmarks"},{"location":"widgets/06_anatomical_fiducials.html#ac-point","text":"The anterior commissure.","title":"AC point"},{"location":"widgets/06_anatomical_fiducials.html#pc-point","text":"The posterior commissure.","title":"PC point"},{"location":"widgets/06_anatomical_fiducials.html#midline-points","text":"","title":"Midline Points"},{"location":"widgets/06_anatomical_fiducials.html#genu","text":"Genu.","title":"Genu"},{"location":"widgets/06_anatomical_fiducials.html#infracollicular-sulcus","text":"The infracollicular sulcus.","title":"Infracollicular Sulcus"},{"location":"widgets/06_anatomical_fiducials.html#superior-interpeduncular-fossa","text":"The superior interpeduncular fossa.","title":"Superior interpeduncular fossa"},{"location":"widgets/07_preoperative_planning.html","text":"Note To navigate through the 2D view: Move crosshairs in all views : hold Shift while moving the mouse Zoom in/out : hold the right mouse button while moving mouse up/down (can hold Control/Command and scroll) Pan (translate) scan : hold middle-mouse button while moving the mouse Adding/Modifying a Plan \u00b6 \u2003\u2003The planning module contains two coordinate groupboxes, one for ACPC space and the other for stereotactic space. The coordinates are linked to the position of the crosshairs, when the crosshairs move the coordinates are updated in real-time. The preop planning module. \u2003\u2003 trajectoryGuide links objects and data in the scene to the plan name. When you switch between plans, the values in the coordinate boxes will update to the current plan values. Before setting a target/entry, you will need to add a new plan. Click Add in the Plan Name groupbox and set a name for the current plan. Defining the entry/target point is similar to the previous Anatomical fiducials widget except you can also enter exact coordinate values into the ACPC/Stereotactic space coordinate boxes and press \"Update Crosshairs\" to move the crosshairs to the specified coordinates. Warning Only enter stereotactic based coordinates into the stereotactic coordinate boxes Only enter ACPC based coordinates into the ACPC space boxes","title":"Preoperative Planning"},{"location":"widgets/07_preoperative_planning.html#addingmodifying-a-plan","text":"The planning module contains two coordinate groupboxes, one for ACPC space and the other for stereotactic space. The coordinates are linked to the position of the crosshairs, when the crosshairs move the coordinates are updated in real-time. The preop planning module. \u2003\u2003 trajectoryGuide links objects and data in the scene to the plan name. When you switch between plans, the values in the coordinate boxes will update to the current plan values. Before setting a target/entry, you will need to add a new plan. Click Add in the Plan Name groupbox and set a name for the current plan. Defining the entry/target point is similar to the previous Anatomical fiducials widget except you can also enter exact coordinate values into the ACPC/Stereotactic space coordinate boxes and press \"Update Crosshairs\" to move the crosshairs to the specified coordinates. Warning Only enter stereotactic based coordinates into the stereotactic coordinate boxes Only enter ACPC based coordinates into the ACPC space boxes","title":"Adding/Modifying a Plan"},{"location":"widgets/08_intraoperative_planning.html","text":"","title":"Intraoperative Planning"},{"location":"widgets/09_postoperative_localization.html","text":"Locating postoperative electrode \u00b6 For now, electrode localization in trajectoryGuide is achieved by manually defining the bottom and top of each electrode. The user should place the postoperative imaging volume (CT and/or MRI) inside the patient folder, re-load trajectoryGuide, and run the registration step. Once the postoperative volume is aligned with the reference image volume it can be used to locate the electrode(s). \u2003\u2003The user must indicate the plan that is associated with the electrode being localized. If only postoperative localization is being performed for the patient a plan name can be defined within this module. The user is then asked to place a fiducial marker at the very tip of the electrode to mark the \u201ctarget\u201d and another fiducial point near where it exists from the skull to indicate the \u201centry\u201d point. Once the two points are placed the \u201cConfirm Electrode\u201d button can be pressed and the postoperative electrode will be rendered in the 2D and 3D views. The postop localization module.","title":"Postoperative Localization"},{"location":"widgets/09_postoperative_localization.html#locating-postoperative-electrode","text":"For now, electrode localization in trajectoryGuide is achieved by manually defining the bottom and top of each electrode. The user should place the postoperative imaging volume (CT and/or MRI) inside the patient folder, re-load trajectoryGuide, and run the registration step. Once the postoperative volume is aligned with the reference image volume it can be used to locate the electrode(s). \u2003\u2003The user must indicate the plan that is associated with the electrode being localized. If only postoperative localization is being performed for the patient a plan name can be defined within this module. The user is then asked to place a fiducial marker at the very tip of the electrode to mark the \u201ctarget\u201d and another fiducial point near where it exists from the skull to indicate the \u201centry\u201d point. Once the two points are placed the \u201cConfirm Electrode\u201d button can be pressed and the postoperative electrode will be rendered in the 2D and 3D views. The postop localization module.","title":"Locating postoperative electrode"},{"location":"widgets/10_postoperative_programming.html","text":"Volume of activated tissue \u00b6 The volume of activated tissue (VAT) also referred to as the volume of tissue activated (VTA) is a model the predicts the extent and location of neural activation produced by stimulation. In trajectoryGuide, the model proposed by Dembek et al. (2017) has been utilized since it does not require image processing to be conducted prior to VAT computation 1 . The calculation of the stimulation field radius based on the DBS stimulation parameters is described the following equation: \\[ r=\\left ( \\frac{pw}{90 \\mu s} \\right )*\\sqrt{0.72\\frac{Vm}{A}*\\frac{I}{165 V/m}} \\] \u2003\u2003where pw is the pulse width (microseconds), A is the amplitude of stimulation (voltage or milliamperes), and I is the impedance (Ohms) of the electrode contact being used for stimulation. The value 0.72 Vm is a constant validated by Dembek et al. (2017) in a previous study 1 . A more complex stimulation field model will eventually be incorporated into trajectoryGuide that can handle bipolar stimulation. For now, only a monopolar stimulation model can be generated. To generate the VAT models in trajectoryGuide, the user needs to input the stimulation parameters including the active contact, stimulation amplitude, frequency, pulse width, and impedance The postop volume of activated tissue module. 1 T. A. Dembek et al., \u201cProbabilistic mapping of deep brain stimulation effects in essential tremor.,\u201d NeuroImage Clin., vol. 13, pp. 164\u2013173, 2017, doi: 10.1016/j.nicl.2016.11.019","title":"Postoperative Programming"},{"location":"widgets/10_postoperative_programming.html#volume-of-activated-tissue","text":"The volume of activated tissue (VAT) also referred to as the volume of tissue activated (VTA) is a model the predicts the extent and location of neural activation produced by stimulation. In trajectoryGuide, the model proposed by Dembek et al. (2017) has been utilized since it does not require image processing to be conducted prior to VAT computation 1 . The calculation of the stimulation field radius based on the DBS stimulation parameters is described the following equation: \\[ r=\\left ( \\frac{pw}{90 \\mu s} \\right )*\\sqrt{0.72\\frac{Vm}{A}*\\frac{I}{165 V/m}} \\] \u2003\u2003where pw is the pulse width (microseconds), A is the amplitude of stimulation (voltage or milliamperes), and I is the impedance (Ohms) of the electrode contact being used for stimulation. The value 0.72 Vm is a constant validated by Dembek et al. (2017) in a previous study 1 . A more complex stimulation field model will eventually be incorporated into trajectoryGuide that can handle bipolar stimulation. For now, only a monopolar stimulation model can be generated. To generate the VAT models in trajectoryGuide, the user needs to input the stimulation parameters including the active contact, stimulation amplitude, frequency, pulse width, and impedance The postop volume of activated tissue module. 1 T. A. Dembek et al., \u201cProbabilistic mapping of deep brain stimulation effects in essential tremor.,\u201d NeuroImage Clin., vol. 13, pp. 164\u2013173, 2017, doi: 10.1016/j.nicl.2016.11.019","title":"Volume of activated tissue"},{"location":"widgets/11_data_view.html","text":"","title":"Data View"}]}